{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, label_binarize\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, NMF, TruncatedSVD\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libscores import bac_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_info(file_name):\n",
    "    result = []\n",
    "    \n",
    "    for line in file(file_name):\n",
    "        key, value = line.strip().split('=')\n",
    "        key = key.strip()\n",
    "        value = value.strip().strip(\"'\")\n",
    "        if value.isdigit():\n",
    "            value = int(value)\n",
    "        result.append((key, value))\n",
    "    \n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feat_num': 27,\n",
       " 'feat_type': 'Numerical',\n",
       " 'has_categorical': 0,\n",
       " 'has_missing': 0,\n",
       " 'is_sparse': 0,\n",
       " 'label_num': 100,\n",
       " 'metric': 'bac_metric',\n",
       " 'name': 'helena',\n",
       " 'target_num': 100,\n",
       " 'target_type': 'Categorical',\n",
       " 'task': 'multiclass.classification',\n",
       " 'test_num': 18628,\n",
       " 'time_budget': 1200,\n",
       " 'train_num': 65196,\n",
       " 'usage': 'AutoML challenge 2014',\n",
       " 'valid_num': 9314}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public = read_info('data/set3_helena/helena_public.info')\n",
    "public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_float_dense_features(file_name):\n",
    "    result = list()\n",
    "    for line in file(file_name):\n",
    "        row = [float(f) for f in line.strip().split(' ')]\n",
    "        result.append(row)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_multilabels(file_name):\n",
    "    result = list()\n",
    "    for line in file(file_name):\n",
    "        row = [f for f in line.strip().split(' ')]\n",
    "        result.append(row.index('1'))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65196, 27) (65196,) (100,)\n",
      "(9314, 27) (18628, 27)\n"
     ]
    }
   ],
   "source": [
    "X = read_float_dense_features('data/set3_helena/helena_train.data')\n",
    "y = read_multilabels('data/set3_helena/helena_train.solution')\n",
    "\n",
    "X_valid = read_float_dense_features('data/set3_helena/helena_valid.data')\n",
    "X_test  = read_float_dense_features('data/set3_helena/helena_test.data')\n",
    "\n",
    "print X.shape, y.shape, np.unique(y).shape\n",
    "print X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=True, copy=False)\n",
    "X = scaler.fit_transform(X)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:33,  3.68s/it]"
     ]
    }
   ],
   "source": [
    "n_iter = 5\n",
    "cv = StratifiedShuffleSplit(y, n_iter=n_iter, test_size=0.25, random_state=1)\n",
    "\n",
    "scores = []\n",
    "it = 1\n",
    "for train, test in cv:\n",
    "    print 'iteration %d' % it\n",
    "\n",
    "    model = LogisticRegression(n_jobs=-1)\n",
    "    \n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    N, d = X_train.shape\n",
    "\n",
    "    sample_size = list(range(5000, N, 5000)) + [N]\n",
    "    for j in tqdm(sample_size):\n",
    "        model.fit(X_train[:j], y_train[:j])\n",
    "        y_pred = model.predict_proba(X[test])\n",
    "\n",
    "        score = bac_metric(label_binarize(y[test], classes=classes), y_pred)\n",
    "        scores.append((it, j, score))\n",
    "\n",
    "    it = it + 1\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning = pd.DataFrame(scores, columns=['it', 'sample_size', 'score'])\n",
    "\n",
    "for it, grp in learning.groupby('it'):\n",
    "    plt.plot(grp.sample_size, grp.score)\n",
    "\n",
    "mean_score = learning.groupby('sample_size').score.mean()\n",
    "plt.plot(mean_score.index, mean_score.values, color='black', linewidth=2)\n",
    "\n",
    "plt.title('Learning curves')\n",
    "plt.xlabel('Sample size')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.127341226108 0.0\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'logreg': LogisticRegression(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'cv_train_size': 8000,\n",
    "    'model': 'logreg'\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', models[params['model']])\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'model__penalty': 'l2',\n",
    "    'model__C': 1000,\n",
    "}\n",
    "pipeline.set_params(**pipe_params)\n",
    "\n",
    "n_iter = 5\n",
    "cv = StratifiedShuffleSplit(y, n_iter=n_iter, train_size=params['cv_train_size'], random_state=1)\n",
    "\n",
    "scores = []\n",
    "for train, test in tqdm(cv):\n",
    "    pipeline.fit(X_input[train], y[train])\n",
    "    \n",
    "    y_pred = pipeline.predict_proba(X_input[test])\n",
    "    y_test = label_binarize(y[test], classes=classes)\n",
    "    score = bac_metric(y_test, y_pred, task='multiclass.classification')\n",
    "    scores.append(score)\n",
    "\n",
    "params.update(pipe_params)\n",
    "results.append((params, np.mean(score), np.std(score)))\n",
    "print np.mean(score), np.std(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.12734 ± 0.00000, params: {'model__C': 1000, 'model': 'logreg', 'model__penalty': 'l2', 'cv_train_size': 8000}\n"
     ]
    }
   ],
   "source": [
    "for p, s, std in reversed(results[-5:]):\n",
    "    print u'score: %0.5f ± %0.5f, params: %s' % (s, std, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('model', LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_valid_score = pipeline.predict_proba(X_valid)\n",
    "y_test_score = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('submission/helena_valid.predict', y_valid_score, fmt='%0.10f')\n",
    "np.savetxt('submission/helena_test.predict', y_test_score, fmt='%0.10f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
