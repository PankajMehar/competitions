{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('./site_dic.pkl', 'rb') as f:\n",
    "    site_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_visits(file):\n",
    "    df_alice = pd.read_csv(file)\n",
    "    df_alice.site = df_alice.site.apply(site_dict.get)\n",
    "    df_alice.timestamp = pd.to_datetime(df_alice.timestamp)\n",
    "\n",
    "    cnt = df_alice.site.value_counts()\n",
    "    total = cnt.sum()\n",
    "    cnt = cnt[cnt > 5] / total\n",
    "\n",
    "    return {str(k): v for k, v in cnt.to_dict().items()}\n",
    "\n",
    "alice_weight = get_visits('train/Alice_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "times = ['time%d' % i for i in range(1, 11)]\n",
    "\n",
    "df_train = pd.read_csv('train_sessions.csv', dtype={s: 'str' for s in sites})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    s = 'site%d' % i\n",
    "    df_train[s] = df_train[s].fillna('na')\n",
    "    \n",
    "    t = 'time%d' % i\n",
    "    df_train[t] = pd.to_datetime(df_train[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by='time1').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_train\n",
    "df['sites'] = df.site1 + ' ' + df.site2 + ' ' + df.site3 + ' ' + df.site4 + ' ' + df.site5 + ' ' + \\\n",
    "              df.site6 + ' ' + df.site7 + ' ' + df.site8 + ' ' + df.site9 + ' ' + df.site10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['alice_weight'] = df_train[sites].applymap(alice_weight.get).mean(axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer(token_pattern='\\S+', min_df=10, max_df=0.5, stop_words={'na'}, ngram_range=(1, 3))\n",
    "X_ohe = cv.fit_transform(df_train.sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['month'] = 12 * (df_train.time1.dt.year - 2013) + df_train.time1.dt.month\n",
    "df_train['hour_start'] = df_train.time1.dt.hour\n",
    "df_train['weekday'] = df_train.time1.dt.weekday\n",
    "df_train['weekend'] = df_train.time1.dt.weekday > 5\n",
    "df_train['before_noon'] = df_train.hour_start < 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_hour_end(row):\n",
    "    last_t = None\n",
    "\n",
    "    for s, t in zip(sites, times):\n",
    "        if row[s] != 'na':\n",
    "            last_t = row[t]\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return last_t.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['hour_end'] = df_train.apply(calc_hour_end, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_T = df_train[times].T\n",
    "df_train_T_diff = df_train_T.diff()\n",
    "df_train_T_diff[df_train_T.isnull()] = np.nan\n",
    "\n",
    "df_train['diff_min'] = df_train_T_diff.min(axis=0).dt.seconds.fillna(-1)\n",
    "df_train['diff_std'] = df_train_T_diff.std(axis=0).dt.seconds.fillna(-1)\n",
    "#df_train['diff_mean'] = df_train_T_diff.mean(axis=0).dt.seconds.fillna(-1)\n",
    "#df_train['diff_max'] = df_train_T_diff.max(axis=0).dt.seconds.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "has_na = (df_train[sites] == 'na').any(axis=1)\n",
    "df_train['uniq_sites'] = df_train[sites].nunique(axis=1) - has_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_ohe = OneHotEncoder(dtype=np.uint8)\n",
    "X_time = time_ohe.fit_transform(df_train[['hour_start', 'hour_end', 'weekday', 'weekend',\n",
    "                                          'before_noon', 'uniq_sites']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_scale = ['hour_start']\n",
    "X_num = df_train[num_scale].values.astype('float')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_num = scaler.fit_transform(X_num)\n",
    "\n",
    "num_nonscale = ['month', 'diff_std', 'diff_min']\n",
    "X_num = np.hstack([X_num, df_train[num_nonscale].values.astype('float')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df_train.target.values\n",
    "X = sp.hstack([X_ohe, X_time, X_num], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(df_train) // 10\n",
    "\n",
    "Xn = X[int(2*n):]\n",
    "yn = y[int(2*n):]\n",
    "\n",
    "i = 3\n",
    "X_train = Xn[:-i*n]\n",
    "y_train = yn[:-i*n]\n",
    "\n",
    "X_test = X[-i*n:]\n",
    "y_test = y[-i*n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 1, 1: 3}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=1,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1, class_weight={0: 1, 1: 3})\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96908217093921034"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svm.decision_function(X_test)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96893067261338606"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svm.decision_function(X_test)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 1, 1: 3}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=1,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1, class_weight={0: 1, 1: 3})\n",
    "svm.fit(Xn, yn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_sessions.csv', dtype={s: 'str' for s in sites})\n",
    "\n",
    "for i in range(1, 11):\n",
    "    s = 'site%d' % i\n",
    "    df_test[s] = df_test[s].fillna('na')\n",
    "\n",
    "    t = 'time%d' % i\n",
    "    df_test[t] = pd.to_datetime(df_test[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['alice_weight'] = df_test[sites].applymap(alice_weight.get).mean(axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['month'] = 12 * (df_test.time1.dt.year - 2013) + df_test.time1.dt.month\n",
    "df_test['hour_start'] = df_test.time1.dt.hour\n",
    "df_test['weekday'] = df_test.time1.dt.weekday\n",
    "df_test['weekend'] = df_test.time1.dt.weekday > 5\n",
    "df_test['before_noon'] = df_test.hour_start < 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_T = df_test[times].T\n",
    "df_test_T_diff = df_test_T.diff()\n",
    "df_test_T_diff[df_test_T.isnull()] = np.nan\n",
    "\n",
    "df_test['diff_min'] = df_test_T_diff.min(axis=0).dt.seconds.fillna(-1)\n",
    "df_test['diff_std'] = df_test_T_diff.std(axis=0).dt.seconds.fillna(-1)\n",
    "#df_train['diff_mean'] = df_train_T_diff.mean(axis=0).dt.seconds.fillna(-1)\n",
    "#df_train['diff_max'] = df_train_T_diff.max(axis=0).dt.seconds.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['hour_end'] = df_test.apply(calc_hour_end, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "has_na = (df_test[sites] == 'na').any(axis=1)\n",
    "df_test['uniq_sites'] = df_test[sites].nunique(axis=1) - has_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_test\n",
    "df['sites'] = df.site1 + ' ' + df.site2 + ' ' + df.site3 + ' ' + df.site4 + ' ' + df.site5 + ' ' + \\\n",
    "              df.site6 + ' ' + df.site7 + ' ' + df.site8 + ' ' + df.site9 + ' ' + df.site10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_ohe = cv.transform(df_test.sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_time = time_ohe.transform(df_test[['hour_start', 'hour_end', 'weekday', 'weekend',\n",
    "                                          'before_noon', 'uniq_sites']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_num = df_test[num_scale].values.astype('float')\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "X_test_num = np.hstack([X_test_num, df_test[num_nonscale].values.astype('float')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = sp.hstack([X_test_ohe, X_test_time, X_test_num], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = svm.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame()\n",
    "df_res['session_id'] = df_test.session_id\n",
    "df_res['target'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_res.to_csv('wow-so-doge-2n-v5.csv', index=False)\n",
    "!gzip wow-so-doge-2n-v5.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
