{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "times = ['time%d' % i for i in range(1, 11)]\n",
    "\n",
    "df_train = pd.read_csv('train_sessions.csv', dtype={s: 'str' for s in sites})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    s = 'site%d' % i\n",
    "    df_train[s] = df_train[s].fillna('na')\n",
    "    \n",
    "    t = 'time%d' % i\n",
    "    df_train[t] = pd.to_datetime(df_train[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_T = df_train[times].T\n",
    "df_train_T_diff = df_train_T.diff()\n",
    "df_train_T_diff[df_train_T.isnull()] = np.nan\n",
    "\n",
    "df_train['diff_min'] = df_train_T_diff.min(axis=0).dt.seconds.fillna(-1)\n",
    "df_train['diff_std'] = df_train_T_diff.std(axis=0).dt.seconds.fillna(-1)\n",
    "df_train['diff_mean'] = df_train_T_diff.mean(axis=0).dt.seconds.fillna(-1)\n",
    "df_train['diff_max'] = df_train_T_diff.max(axis=0).dt.seconds.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by='time1').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_train\n",
    "df['sites'] = df.site1 + ' ' + df.site2 + ' ' + df.site3 + ' ' + df.site4 + ' ' + df.site5 + ' ' + \\\n",
    "              df.site6 + ' ' + df.site7 + ' ' + df.site8 + ' ' + df.site9 + ' ' + df.site10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_tfidf13 = TfidfVectorizer(token_pattern='\\S+', min_df=10, max_df=0.5, stop_words={'na'}, ngram_range=(1, 3))\n",
    "X_tfidf13 = cv_tfidf13.fit_transform(df_train.sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['hour_start'] = df_train.time1.dt.hour\n",
    "df_train['weekday'] = df_train.time1.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_ohe = OneHotEncoder(dtype=np.uint8)\n",
    "X_time = time_ohe.fit_transform(df_train[['hour_start', 'weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_num = df_train[['hour_start', 'diff_min', 'diff_max', 'diff_std', 'diff_mean']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_train.target.values\n",
    "X_sparse = sp.hstack([X_tfidf13, X_time], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(df_train) // 10\n",
    "\n",
    "y_train = y[:-n]\n",
    "y_test = y[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_sparse[:-n]\n",
    "X_test = X_sparse[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_num = X_num[:-n]\n",
    "X_test_num = X_num[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "kf = list(kf.split(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0, took 6.761s, auc=0.978\n",
      "C=1.0, took 6.670s, auc=0.983\n",
      "C=1.0, took 6.250s, auc=0.978\n",
      "C=1.0, took 7.303s, auc=0.988\n",
      "C=1.0, took 8.238s, auc=0.986\n",
      "C=1.0, took 8.427s, auc=0.984\n",
      "C=1.0, took 7.116s, auc=0.989\n",
      "C=1.0, took 6.131s, auc=0.987\n",
      "C=1.0, took 7.183s, auc=0.985\n",
      "C=1.0, took 6.913s, auc=0.982\n"
     ]
    }
   ],
   "source": [
    "preds = np.zeros_like(y_train, dtype='float32')\n",
    "\n",
    "C = 1.0\n",
    "\n",
    "for train, val in kf:\n",
    "    t0 = time()\n",
    "\n",
    "    svm = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1)\n",
    "    svm.fit(X_train[train], y_train[train])\n",
    "\n",
    "    y_pred = svm.decision_function(X_train[val])\n",
    "    preds[val] = y_pred\n",
    "    auc = roc_auc_score(y_train[val], y_pred)\n",
    "\n",
    "    print('C=%s, took %.3fs, auc=%.3f' % (C, time() - t0, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "pred_test = svm.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, random_state=1)\n",
    "X_svd = svd.fit_transform(X_tfidf13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_et = np.hstack([X_svd, X_time.toarray()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et_params2 = dict(\n",
    "    n_estimators=50,\n",
    "    criterion='gini',\n",
    "    max_depth=50,\n",
    "    min_samples_split=6,\n",
    "    min_samples_leaf=6,\n",
    "    max_features=10,\n",
    "    bootstrap=False, \n",
    "    n_jobs=-1,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 10.132s, auc=0.975\n",
      "took 10.105s, auc=0.982\n",
      "took 10.211s, auc=0.981\n",
      "took 10.215s, auc=0.988\n",
      "took 10.031s, auc=0.980\n",
      "took 10.043s, auc=0.978\n",
      "took 10.229s, auc=0.987\n",
      "took 10.241s, auc=0.985\n",
      "took 10.124s, auc=0.988\n",
      "took 10.033s, auc=0.985\n"
     ]
    }
   ],
   "source": [
    "preds_et = np.zeros_like(y_train, dtype='float32')\n",
    "\n",
    "for train, val in kf:\n",
    "    t0 = time()\n",
    "\n",
    "    et = ExtraTreesClassifier(**et_params2)\n",
    "    et.fit(X_et[train], y_train[train])\n",
    "\n",
    "    y_pred = et.predict_proba(X_et[val])[:, 1]\n",
    "    preds_et[val] = y_pred\n",
    "    auc = roc_auc_score(y_train[val], y_pred)\n",
    "\n",
    "    print('took %.3fs, auc=%.3f' % (time() - t0, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=50, max_features=10, max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=6,\n",
       "           min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=50, n_jobs=-1, oob_score=False, random_state=1,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(**et_params2)\n",
    "et.fit(X_et[:-n], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_et_test = et.predict_proba(X_et[-n:])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et_params = dict(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=5,\n",
    "    min_samples_split=6,\n",
    "    min_samples_leaf=6,\n",
    "    max_features=3,\n",
    "    bootstrap=False, \n",
    "    n_jobs=-1,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_second = np.hstack([preds.reshape(-1, 1), preds_et.reshape(-1, 1), X_train_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_second_test = np.hstack([pred_test.reshape(-1, 1), pred_et_test.reshape(-1, 1),\n",
    "                           X_test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=5, max_features=3, max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=6,\n",
       "           min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=1,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(**et_params)\n",
    "et.fit(X_second, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9780442064113154"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = et.predict_proba(X_second_test)[:, 1]\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98274939133081174"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = et.predict_proba(X_second_test)[:, 1]\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "kf = list(kf.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = np.zeros_like(y, dtype='float32')\n",
    "\n",
    "C = 1.0\n",
    "\n",
    "for train, val in kf:\n",
    "    svm = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1)\n",
    "    svm.fit(X[train], y[train])\n",
    "\n",
    "    preds[val] = svm.decision_function(X[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1)\n",
    "svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_second = np.hstack([preds.reshape(-1, 1), X_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=15, max_features=2, max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=6,\n",
       "           min_samples_split=6, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=1,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(**et_params)\n",
    "et.fit(X_second, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_sessions.csv', dtype={s: 'str' for s in sites})\n",
    "\n",
    "for i in range(1, 11):\n",
    "    s = 'site%d' % i\n",
    "    df_test[s] = df_test[s].fillna('na')\n",
    "\n",
    "    t = 'time%d' % i\n",
    "    df_test[t] = pd.to_datetime(df_test[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['hour_start'] = df_test.time1.dt.hour\n",
    "df_test['weekday'] = df_test.time1.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_test\n",
    "df['sites'] = df.site1 + ' ' + df.site2 + ' ' + df.site3 + ' ' + df.site4 + ' ' + df.site5 + ' ' + \\\n",
    "              df.site6 + ' ' + df.site7 + ' ' + df.site8 + ' ' + df.site9 + ' ' + df.site10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_ohe = cv_tfidf13.transform(df_test.sites)\n",
    "X_test_time = time_ohe.transform(df_test[['hour_start', 'weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = sp.hstack([X_test_ohe, X_test_time], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = svm.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_T = df_test[times].T\n",
    "df_test_T_diff = df_test_T.diff()\n",
    "df_test_T_diff[df_test_T.isnull()] = np.nan\n",
    "\n",
    "df_test['diff_min'] = df_test_T_diff.min(axis=0).dt.seconds.fillna(-1)\n",
    "df_test['diff_std'] = df_test_T_diff.std(axis=0).dt.seconds.fillna(-1)\n",
    "df_test['diff_mean'] = df_test_T_diff.mean(axis=0).dt.seconds.fillna(-1)\n",
    "df_test['diff_max'] = df_test_T_diff.max(axis=0).dt.seconds.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_num_test = df_test[['hour_start', 'diff_min', 'diff_max', 'diff_std', 'diff_mean']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_second_test = np.hstack([preds.reshape(-1, 1), X_num_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_res = pd.DataFrame()\n",
    "df_res['session_id'] = df_test.session_id\n",
    "df_res['target'] = et.predict_proba(X_second_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_res.to_csv('et01.csv', index=False)\n",
    "!gzip et01.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
