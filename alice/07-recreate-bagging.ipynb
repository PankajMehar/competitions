{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('./site_dic.pkl', 'rb') as f:\n",
    "    site_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "times = ['time%d' % i for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roll(df, window_size, step=1):\n",
    "    n = len(df)\n",
    "    for i in range(0, n, step):\n",
    "        yield df.iloc[i:i+window_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames = []\n",
    "for i in range(1, 11):\n",
    "    colnames.append('time%d' % i)\n",
    "    colnames.append('site%d' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_to_line(batch):\n",
    "    line = []\n",
    "\n",
    "    for t, s in zip(batch.timestamp, batch.site):\n",
    "        line.append(t)\n",
    "        line.append(str(s))\n",
    "\n",
    "    l = len(line) // 2\n",
    "    if l < 10:\n",
    "        need = 10 - l\n",
    "        line.extend([None, 'na'] * need)\n",
    "\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    df.site = df.site.apply(site_dict.get)\n",
    "    df.timestamp = pd.to_datetime(df.timestamp)\n",
    "\n",
    "    df['delta'] = df.timestamp - df.timestamp.shift()\n",
    "\n",
    "    half_hour = 30 * 60\n",
    "    session_change = df.delta.dt.seconds >= half_hour\n",
    "\n",
    "    df['session_id'] = session_change.cumsum().astype(int)\n",
    "\n",
    "    groups = df.groupby('session_id')\n",
    "\n",
    "    lines = []\n",
    "    for sid, group in groups:\n",
    "\n",
    "        windows = roll(group, 10)\n",
    "        for win in windows:\n",
    "            line = batch_to_line(win)\n",
    "            lines.append(line)\n",
    "\n",
    "    df_res = pd.DataFrame(lines, columns=colnames)\n",
    "\n",
    "    user = file_name.split('/')[-1][:-4].lower()\n",
    "    df_res['user'] = user\n",
    "\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_files = sorted(glob('train/*.csv') + glob('train/other_user_logs/*.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with ProcessPoolExecutor() as pool:\n",
    "    progress = tqdm(total=len(all_files))\n",
    "   \n",
    "    futures = []\n",
    " \n",
    "    for file in all_files:\n",
    "        future = pool.submit(read_file, file)\n",
    "        future.add_done_callback(lambda x: progress.update())\n",
    "        futures.append(future)\n",
    " \n",
    "    results = []\n",
    "    for f in futures:\n",
    "        results.append(f.result())\n",
    " \n",
    "    progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat(results)\n",
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_train\n",
    "df['sites'] = df.site1 + ' ' + df.site2 + ' ' + df.site3 + ' ' + df.site4 + ' ' + df.site5 + ' ' + \\\n",
    "              df.site6 + ' ' + df.site7 + ' ' + df.site8 + ' ' + df.site9 + ' ' + df.site10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['target'] = (df_train.user == 'alice_log').astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('recreated.bin', 'wb') as f:\n",
    "    pickle.dump(df_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('recreated.bin', 'rb') as f:\n",
    "    df_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer(token_pattern='\\S+', min_df=10, max_df=0.5, stop_words={'na'}, ngram_range=(1, 1))\n",
    "X_ohe = cv.fit_transform(df_train.sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['hour_start'] = df_train.time1.dt.hour\n",
    "df_train['weekday'] = df_train.time1.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_ohe = OneHotEncoder(dtype=np.uint8)\n",
    "X_time = time_ohe.fit_transform(df_train[['hour_start', 'weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_train.target.values\n",
    "X_sparse = sp.hstack([X_ohe, X_time], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = 0.1\n",
    "lr = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1)\n",
    "bag = BaggingClassifier(base_estimator=lr, n_estimators=4, n_jobs=-1, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.03 s, sys: 428 ms, total: 3.46 s\n",
      "Wall time: 43.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=4, n_jobs=-1, oob_score=False,\n",
       "         random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bag.fit(X_sparse, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_sessions.csv', dtype={s: 'str' for s in sites})\n",
    "\n",
    "for i in range(1, 11):\n",
    "    s = 'site%d' % i\n",
    "    df_test[s] = df_test[s].fillna('na')\n",
    "\n",
    "    t = 'time%d' % i\n",
    "    df_test[t] = pd.to_datetime(df_test[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['hour_start'] = df_test.time1.dt.hour\n",
    "df_test['weekday'] = df_test.time1.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_test\n",
    "df['sites'] = df.site1 + ' ' + df.site2 + ' ' + df.site3 + ' ' + df.site4 + ' ' + df.site5 + ' ' + \\\n",
    "              df.site6 + ' ' + df.site7 + ' ' + df.site8 + ' ' + df.site9 + ' ' + df.site10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_ohe = cv.transform(df_test.sites)\n",
    "X_test_time = time_ohe.transform(df_test[['hour_start', 'weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = sp.hstack([X_test_ohe, X_test_time], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = bag.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame()\n",
    "df_res['session_id'] = df_test.session_id\n",
    "df_res['target'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_res.to_csv('doge2.csv', index=False)\n",
    "!gzip doge2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
