{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('./site_dic.pkl', 'rb') as f:\n",
    "    site_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_session(session, data, username, len_session=10):\n",
    "    item_to_add = ['na', float(\"NaN\")]\n",
    "    session_limit = len_session * 2\n",
    "        \n",
    "    while True:\n",
    "        if len(session) >= session_limit:\n",
    "            break\n",
    "        session += item_to_add\n",
    "    \n",
    "    session.append(username)\n",
    "    data.append(session)\n",
    "\n",
    "def file_to_df(file_path, len_session=10, first_line_file=\"timestamp,site\", shift_window=False):\n",
    "    open_file = open(file_path)\n",
    "    lines = open_file.readlines()\n",
    "    \n",
    "    if \"/\" in file_path:\n",
    "        username = file_path[file_path.rfind(\"/\") + 1:-4]\n",
    "    else:\n",
    "        username = file_path[:-4]\n",
    "        \n",
    "    data = list()\n",
    "    session = list()\n",
    "    ln_count = 0\n",
    "    start_session = None\n",
    "    \n",
    "    if not shift_window:\n",
    "        sw = list()\n",
    "    else:\n",
    "        sw = shift_window\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        ln = lines[i].strip()\n",
    "        if ln == 'timestamp,site' or i in sw:\n",
    "            continue\n",
    "\n",
    "        time, site = ln.split(\",\")\n",
    "        site = str(site_dict[site])\n",
    "        time = datetime.strptime(time, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        if not start_session:\n",
    "            start_session = time\n",
    "\n",
    "        time_diff = (time - start_session).total_seconds()\n",
    "        ln_count += 1\n",
    "\n",
    "        if time_diff > 1800 or ln_count > 10:\n",
    "            add_session(session, \n",
    "                        data, \n",
    "                        username, \n",
    "                        len_session=len_session)\n",
    "\n",
    "            start_session = time\n",
    "            time_diff = 0\n",
    "            ln_count = 1\n",
    "            session = list()\n",
    "\n",
    "        session += [site, time]\n",
    "\n",
    "        if i == len(lines) - 1:\n",
    "            add_session(session, \n",
    "                        data, username, \n",
    "                        len_session=len_session,)\n",
    "        \n",
    "    columns = list()\n",
    "    for i in range(1, len_session + 1):\n",
    "        columns += [\"site\" + str(i), \"time\" + str(i)]\n",
    "\n",
    "    columns += [\"user\"]\n",
    "    \n",
    "    return pd.DataFrame.from_records(data, columns=columns)\n",
    "\n",
    "def get_full_df(shift_count=0):\n",
    "    files = sorted(glob('train/*.csv') + glob('train/other_user_logs/*.csv'))\n",
    "\n",
    "    frames = list()\n",
    "    for i in range(0, shift_count + 1):\n",
    "        shift_window = list(range(i))\n",
    "        for file in files:\n",
    "            df = file_to_df(file, shift_window=shift_window)\n",
    "            frames.append(df)\n",
    "    \n",
    "    return pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full = get_full_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_full['target'] = (df_full.user == 'Alice_log').astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = df_full.sort_values(by='time1').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "times = ['time%d' % i for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_train\n",
    "df['sites'] = df.site1 + ' ' + df.site2 + ' ' + df.site3 + ' ' + df.site4 + ' ' + df.site5 + ' ' + \\\n",
    "              df.site6 + ' ' + df.site7 + ' ' + df.site8 + ' ' + df.site9 + ' ' + df.site10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer(token_pattern='\\S+', min_df=10, max_df=0.5, stop_words={'na'}, ngram_range=(1, 3))\n",
    "X_ohe = cv.fit_transform(df_train.sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['hour_start'] = df_train.time1.dt.hour\n",
    "df_train['weekday'] = df_train.time1.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_ohe = OneHotEncoder(dtype=np.uint8)\n",
    "X_time = time_ohe.fit_transform(df_train[['hour_start', 'weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df_train.target.values\n",
    "X_sparse = sp.hstack([X_ohe, X_time], format='csr') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(df_train) // 10\n",
    "\n",
    "X_train = X_sparse[:-n]\n",
    "y_train = y[:-n]\n",
    "\n",
    "X_test = X_sparse[-n:]\n",
    "y_test = y[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98141339869281052"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = 1\n",
    "svm = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_alice = svm.decision_function(X_test)\n",
    "roc_auc_score(y_test, y_pred_alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_all = df_train.user.values\n",
    "y_all_train = y_all[:-n]\n",
    "y_all_test = y_all[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]CPU times: user 4h 34min 17s, sys: 6min 29s, total: 4h 40min 47s\n",
      "Wall time: 1h 10min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "C = 1\n",
    "svm = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1, n_jobs=12, verbose=True)\n",
    "svm.fit(X_train, y_all_train)\n",
    "\n",
    "#y_pred = svm.decision_function(X_test)\n",
    "#roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = svm.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_s = StandardScaler().fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrigorev/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/agrigorev/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "y_pred_a = StandardScaler().fit_transform(y_pred_alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = y_pred_s.T.dot(y_pred_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1138, 1196, 1442, ...,  323,  764,    0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]CPU times: user 5h 3min 22s, sys: 7min 17s, total: 5h 10min 39s\n",
      "Wall time: 1h 17min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "C = 1\n",
    "svm_full = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1, n_jobs=12, verbose=True)\n",
    "svm_full.fit(X_sparse, y_all)\n",
    "\n",
    "#y_pred = svm.decision_function(X_test)\n",
    "#roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LogisticRegression(penalty='l2', dual=False, C=C, random_state=1)\n",
    "svm.fit(X_sparse, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_sessions.csv', dtype={s: 'str' for s in sites})\n",
    "\n",
    "for i in range(1, 11):\n",
    "    s = 'site%d' % i\n",
    "    df_test[s] = df_test[s].fillna('na')\n",
    "\n",
    "    t = 'time%d' % i\n",
    "    df_test[t] = pd.to_datetime(df_test[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test['hour_start'] = df_test.time1.dt.hour\n",
    "df_test['weekday'] = df_test.time1.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_test\n",
    "df['sites'] = df.site1 + ' ' + df.site2 + ' ' + df.site3 + ' ' + df.site4 + ' ' + df.site5 + ' ' + \\\n",
    "              df.site6 + ' ' + df.site7 + ' ' + df.site8 + ' ' + df.site9 + ' ' + df.site10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_ohe = cv.transform(df_test.sites)\n",
    "\n",
    "X_test_time = time_ohe.transform(df_test[['hour_start', 'weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = sp.hstack([X_test_ohe, X_test_time], format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = svm.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_res = pd.DataFrame()\n",
    "df_res['session_id'] = df_test.session_id\n",
    "df_res['target'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_res.to_csv('doge4.csv', index=False)\n",
    "!gzip doge4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
