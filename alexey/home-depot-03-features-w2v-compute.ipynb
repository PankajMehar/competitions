{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/agrigorev/notebooks/home-depot/homedepot\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Google_spell_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from unidecode import unidecode\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_path = '/home/agrigorev/notebooks/home-depot/input'\n",
    "\n",
    "df_train = pd.read_csv(root_path + '/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv(root_path + '/test.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv(root_path + '/product_descriptions.csv')\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_products = df_all.groupby('product_uid')[['product_title', 'product_uid']].head(n=1)\n",
    "df_products.fillna('', inplace=1)\n",
    "\n",
    "df_all.drop(['product_title'], axis=1, inplace=1)\n",
    "\n",
    "df_products = df_products.merge(df_pro_desc, on='product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_attr = pd.read_csv(root_path + '/attributes.csv', encoding='utf-8')\n",
    "df_attr.name = df_attr.name.str.lower()\n",
    "df_brand = df_attr[df_attr.name == \"mfg brand name\"][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"brand\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_colors(group):\n",
    "    if len(group) != 2:\n",
    "        return list(group)[0]\n",
    "    \n",
    "    el1, el2 = list(group)\n",
    "    if el1 in el2:\n",
    "        return el2\n",
    "    elif el2 in el1:\n",
    "        return el1\n",
    "    else:\n",
    "        return ' '.join(set(group))\n",
    "\n",
    "df_colors = df_attr[df_attr.name.isin(['color/finish', 'color family'])].fillna('')\n",
    "df_colors = df_colors.groupby('product_uid').value.agg(dict(color=combine_colors)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_material = df_attr[df_attr.name == u'material'].copy()\n",
    "df_material.value = df_material.value + ' '\n",
    "df_material = df_material.groupby('product_uid').value.sum()\n",
    "df_material = df_material.reset_index()\n",
    "df_material.rename(columns=dict(value='material'), inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attr_names = [\n",
    "    u'bullet01', u'bullet02', u'bullet03', u'bullet04', u'bullet05', \n",
    "    u'bullet06', u'bullet07', u'bullet08', u'bullet09', u'bullet10', \n",
    "    u'bullet11', u'bullet12', u'bullet13', u'bullet14', u'bullet15', \n",
    "    u'bullet16', u'bullet17', u'bullet18', u'bullet19', u'bullet20', \n",
    "    u'bullet21', u'bullet22']\n",
    "\n",
    "df_attr_selected = df_attr[df_attr.name.isin(attr_names)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spell_check = Google_spell_check.spell_check_dict\n",
    "\n",
    "def get_or_identity(query):\n",
    "    return spell_check.get(query, query)\n",
    "\n",
    "df_all.search_term = df_all.search_term.apply(get_or_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_correction(line):\n",
    "    return line.strip().split('->')\n",
    "\n",
    "with open('one-word-corrections.txt', 'r') as f:\n",
    "    corrections = [parse_correction(s) for s in f.readlines()]\n",
    "    corrections = {k: v.split(' ') for (k, v) in corrections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = {'a', 'from', 'only', 'do', 'with', 'the', 'and', 'the', 'for', 'up', 'to', 'be',\n",
    "             'per'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_stem(s): \n",
    "    if not isinstance(s, (str, unicode)):\n",
    "        return []\n",
    "\n",
    "    if isinstance(s, str):\n",
    "        s = unicode(s.decode('utf-8'))\n",
    "\n",
    "    # some title edits?\n",
    "    s = s.replace(\"&quot;\",\" \")\n",
    "    s = s.replace(u\"è_\",\" \")\n",
    "    s = s.replace(u\"å¡\",\" \")\n",
    "    s = s.replace(u\"Û\",\" \")\n",
    "    s = s.replace(u\"åÊ\",\" \")\n",
    "    s = s.replace(u\"ÛÒ\",\" \")\n",
    "    s = s.replace(u\"Ûª\",\" \")\n",
    "    s = s.replace(u\"ÛÜ\",\" \")\n",
    "    s = s.replace(u\"Û÷\",\" \")\n",
    "    s = s.replace(u\"ÈÀ\",\" \")\n",
    "    s = s.replace(u\"ã¢\",\" \")        \n",
    "    s = s.replace(u\"Ã¥Â¡\",\" \")\n",
    "    s = s.replace(u\"ã¨_\",\" \")\n",
    "\n",
    "    s = re.sub(r\"(\\w)\\.([A-Z])\", r\"\\1 \\2\", s) #Split words with a.A?\n",
    "    s = s.replace(\"U.S.\",\" US \")\n",
    "    s = s.lower()\n",
    "\n",
    "    # some title edits END?\n",
    "    s = s.replace(\"&#39;s\",\" \")\n",
    "\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = s.replace(\",\",\"\") #could be number / segment later?\n",
    "    s = s.replace(\"$\",\" \")\n",
    "    s = s.replace(\"+\",\" plus \")\n",
    "    s = s.replace(\";\",\" \")\n",
    "    s = s.replace(\":\",\" \")\n",
    "    s = s.replace(\"&amp;\",\" \")\n",
    "    s = s.replace(\"&amp\",\" \")\n",
    "    s = s.replace(\"?\",\" \")\n",
    "    s = s.replace(\"-\",\" \")\n",
    "    s = s.replace(\"#\",\" \")\n",
    "    s = s.replace(\"(\",\" \")\n",
    "    s = s.replace(\")\",\" \")\n",
    "    s = s.replace(\"//\",\"/\")\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\" / \",\" ovr \")\n",
    "    s = s.replace(\" \\\\ \",\" \")\n",
    "    s = s.replace(\".\",\" . \")\n",
    "\n",
    "    s = re.sub(r\"(^\\.|/)\", r\" \", s)\n",
    "    s = re.sub(r\"(\\.|/)$\", r\" \", s)\n",
    "    s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n",
    "    s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n",
    "    s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "    s = re.sub(r\"([a-z])( *)/( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "\n",
    "    s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(square|sq)\\.?\", r\"\\1sq \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(cubic|cu)\\.?\", r\"\\1cu \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(degrees|degree)\\.?\", r\"\\1deg \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(volts|volt|v)\\.?\", r\"\\1volt \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(watts|watt|w)\\.?\", r\"\\1watt \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp \", s)\n",
    "\n",
    "    s = s.replace(\" x \", \" xby \")\n",
    "    s = s.replace(\"*\", \" xby \")\n",
    "    s = s.replace(\" by \", \" xby\")\n",
    "    s = s.replace(\"x0\", \" xby 0\")\n",
    "    s = s.replace(\"x1\", \" xby 1\")\n",
    "    s = s.replace(\"x2\", \" xby 2\")\n",
    "    s = s.replace(\"x3\", \" xby 3\")\n",
    "    s = s.replace(\"x4\", \" xby 4\")\n",
    "    s = s.replace(\"x5\", \" xby 5\")\n",
    "    s = s.replace(\"x6\", \" xby 6\")\n",
    "    s = s.replace(\"x7\", \" xby 7\")\n",
    "    s = s.replace(\"x8\", \" xby 8\")\n",
    "    s = s.replace(\"x9\", \" xby 9\")\n",
    "    s = s.replace(\"0x\", \"0 xby \")\n",
    "    s = s.replace(\"1x\", \"1 xby \")\n",
    "    s = s.replace(\"2x\", \"2 xby \")\n",
    "    s = s.replace(\"3x\", \"3 xby \")\n",
    "    s = s.replace(\"4x\", \"4 xby \")\n",
    "    s = s.replace(\"5x\", \"5 xby \")\n",
    "    s = s.replace(\"6x\", \"6 xby \")\n",
    "    s = s.replace(\"7x\", \"7 xby \")\n",
    "    s = s.replace(\"8x\", \"8 xby \")\n",
    "    s = s.replace(\"9x\", \"9 xby \")\n",
    "\n",
    "    s = s.replace(\"&\",\" \")\n",
    "    s = s.replace(\"'\",\" \")\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = s.replace(\" . \",\" \")\n",
    "\n",
    "    s = unidecode(s.lower())\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    for z in s.split(\" \"):\n",
    "        z = z.strip()\n",
    "        if not z:\n",
    "            continue\n",
    "        if z in stopwords:\n",
    "            continue\n",
    "\n",
    "        if z in corrections:\n",
    "            result.extend(corrections[z])\n",
    "        else:\n",
    "            result.append(z)\n",
    "\n",
    "    return [stemmer.stem(z) for z in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "pool = Pool(processes=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_parallel(pool, series, function):\n",
    "    return pool.map(function, series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 128.64880s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "df_all.search_term = process_parallel(pool, df_all.search_term, str_stem)\n",
    "df_products.product_title = process_parallel(pool, df_products.product_title, str_stem)\n",
    "df_products.product_description = process_parallel(pool, df_products.product_description, str_stem)\n",
    "\n",
    "df_brand.brand = process_parallel(pool, df_brand.brand, str_stem)\n",
    "df_colors.color = process_parallel(pool, df_colors.color, str_stem)\n",
    "df_material.material = process_parallel(pool, df_material.material, str_stem)\n",
    "df_attr_selected.value = process_parallel(pool, df_attr_selected.value, str_stem)\n",
    "\n",
    "print 'took %0.5fs.' % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_attr_pivot = df_attr_selected.pivot(index='product_uid', columns='name')\n",
    "df_attr_pivot.columns = df_attr_pivot.columns.levels[1]\n",
    "df_attr_pivot.reset_index(inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all_merged = df_all\n",
    "df_all_merged = df_all_merged.merge(df_products, how='left', on='product_uid')\n",
    "df_all_merged = df_all_merged.merge(df_brand, how='left', on='product_uid')\n",
    "df_all_merged = df_all_merged.merge(df_colors, how='left', on='product_uid')\n",
    "df_all_merged = df_all_merged.merge(df_material, how='left', on='product_uid')\n",
    "df_all_merged = df_all_merged.merge(df_attr_pivot, how='left', on='product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_fields = ['brand', 'product_title', 'product_description', 'color', 'material'] + attr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_ref = []\n",
    "\n",
    "def nan_to_list(val):\n",
    "    if isinstance(val, float) and np.isnan(val):\n",
    "        return list_ref\n",
    "    return val\n",
    "\n",
    "for c in text_fields:\n",
    "    df_all_merged[c] = df_all_merged[c].apply(nan_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all_merged['all_text'] = df_all_merged[text_fields].sum(axis=1)\n",
    "text_fields = text_fields + ['all_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('home_depot_w2v.bin')\n",
    "dim, = model['cat'].shape\n",
    "\n",
    "def to_w2v(val):\n",
    "    res = np.zeros(dim)\n",
    "    if not val:\n",
    "        return res\n",
    "\n",
    "    for s in val:\n",
    "        if s not in model:\n",
    "            continue\n",
    "        res = res + model[s]\n",
    "    \n",
    "    norm = np.linalg.norm(res)\n",
    "    if norm > 0:\n",
    "        return res / np.linalg.norm(res)\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 175.59549s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "w2v_arrays = {}\n",
    "for c in ['search_term'] + text_fields:\n",
    "    w2v_arrays[c] = process_parallel(pool, df_all_merged[c], to_w2v)\n",
    "\n",
    "print 'took %0.5fs.' % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "search_term_w2v = np.array(w2v_arrays['search_term'])\n",
    "\n",
    "df_w2v_sim = pd.DataFrame({'id': df_all_merged.id})\n",
    "\n",
    "for c in tqdm(text_fields):\n",
    "    col_w2v = np.array(w2v_arrays[c])\n",
    "    df_w2v_sim['w2v_query_' + c] = (search_term_w2v * col_w2v).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_w2v_sim.to_csv('w2v_features_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
