{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/agrigorev/notebooks/home-depot/homedepot\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Google_spell_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from unidecode import unidecode\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_path = '/home/agrigorev/notebooks/home-depot/input'\n",
    "\n",
    "df_train = pd.read_csv(root_path + '/train.csv', encoding=\"ISO-8859-1\")\n",
    "df_test = pd.read_csv(root_path + '/test.csv', encoding=\"ISO-8859-1\")\n",
    "df_pro_desc = pd.read_csv(root_path + '/product_descriptions.csv')\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_products = df_all.groupby('product_uid')[['product_title', 'product_uid']].head(n=1)\n",
    "df_products.fillna('', inplace=1)\n",
    "\n",
    "df_all.drop(['product_title'], axis=1, inplace=1)\n",
    "\n",
    "df_products = df_products.merge(df_pro_desc, on='product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_attr = pd.read_csv(root_path + '/attributes.csv', encoding='utf-8')\n",
    "df_attr.name = df_attr.name.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spell_check = Google_spell_check.spell_check_dict\n",
    "\n",
    "def get_or_identity(query):\n",
    "    return spell_check.get(query, query)\n",
    "\n",
    "df_all.search_term = df_all.search_term.apply(get_or_identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_correction(line):\n",
    "    return line.strip().split('->')\n",
    "\n",
    "with open('one-word-corrections.txt', 'r') as f:\n",
    "    corrections = [parse_correction(s) for s in f.readlines()]\n",
    "    corrections = [s for s in corrections if len(s) == 2]\n",
    "    corrections = {k: v.split(' ') for (k, v) in corrections}\n",
    "\n",
    "with open('many-words-corrections.txt', 'r') as f:\n",
    "    multiword_corrections = [parse_correction(s) for s in f.readlines()]\n",
    "    multiword_corrections = [s for s in multiword_corrections if len(s) == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = {'a', 'from', 'only', 'do', 'with', 'the', 'and', 'for', 'up', 'to', 'be', 'per',\n",
    "            'th', 'on', 'what', 'that'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def str_stem(s): \n",
    "    if not isinstance(s, (str, unicode)):\n",
    "        return []\n",
    "\n",
    "    if isinstance(s, str):\n",
    "        s = unicode(s.decode('utf-8'))\n",
    "\n",
    "    # some title edits?\n",
    "    s = s.replace(\"&quot;\",\" \")\n",
    "    s = s.replace(u\"è_\",\" \")\n",
    "    s = s.replace(u\"å¡\",\" \")\n",
    "    s = s.replace(u\"Û\",\" \")\n",
    "    s = s.replace(u\"åÊ\",\" \")\n",
    "    s = s.replace(u\"ÛÒ\",\" \")\n",
    "    s = s.replace(u\"Ûª\",\" \")\n",
    "    s = s.replace(u\"ÛÜ\",\" \")\n",
    "    s = s.replace(u\"Û÷\",\" \")\n",
    "    s = s.replace(u\"ÈÀ\",\" \")\n",
    "    s = s.replace(u\"ã¢\",\" \")        \n",
    "    s = s.replace(u\"Ã¥Â¡\",\" \")\n",
    "    s = s.replace(u\"ã¨_\",\" \")\n",
    "\n",
    "    s = re.sub(r\"(\\w)\\.([A-Z])\", r\"\\1 \\2\", s) #Split words with a.A?\n",
    "    s = s.replace(\"U.S.\",\" US \")\n",
    "    s = s.lower()\n",
    "\n",
    "    s = re.sub(r\"(\\w)\\.(\\w)\", r\"\\1 \\2\", s)\n",
    "    s = s.replace(\"&#39;s\",\" \")\n",
    "\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = s.replace(\",\",\"\") #could be number / segment later?\n",
    "    s = s.replace(\"$\",\" \")\n",
    "    s = s.replace(\"+\",\" plus \")\n",
    "    s = s.replace(\";\",\" \")\n",
    "    s = s.replace(\":\",\" \")\n",
    "    s = s.replace(\"&amp;\",\" \")\n",
    "    s = s.replace(\"&amp\",\" \")\n",
    "    s = s.replace(\"?\",\" \")\n",
    "    s = s.replace(\"-\",\" \")\n",
    "    s = s.replace(\"#\",\" \")\n",
    "    s = s.replace(\"(\",\" \")\n",
    "    s = s.replace(\")\",\" \")\n",
    "    s = s.replace(\"//\",\"/\")\n",
    "    s = s.replace(\"..\",\".\")\n",
    "    s = s.replace(\" / \",\" ovr \")\n",
    "    s = s.replace(\" \\\\ \",\" \")\n",
    "    s = s.replace(\".\",\" . \")\n",
    "\n",
    "    s = re.sub(r\"(^\\.|/)\", r\" \", s)\n",
    "    s = re.sub(r\"(\\.|/)$\", r\" \", s)\n",
    "    s = re.sub(r\"([0-9])([a-z])\", r\"\\1 \\2\", s)\n",
    "    s = re.sub(r\"([a-z])([0-9])\", r\"\\1 \\2\", s)\n",
    "    s = re.sub(r\"([a-z])( *)\\.( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "    s = re.sub(r\"([a-z])( *)/( *)([a-z])\", r\"\\1 \\4\", s)\n",
    "\n",
    "    s = re.sub(r\"([0-9])( *)\\.( *)([0-9])\", r\"\\1.\\4\", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(inches|inch|in|')\\.?\", r\"\\1in \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(foot|feet|ft|'')\\.?\", r\"\\1ft \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(pounds|pound|lbs|lb)\\.?\", r\"\\1lb \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(square|sq) ?\\.?(feet|foot|ft)\\.?\", r\"\\1sqft \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(square|sq)\\.?\", r\"\\1sq \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(cubic|cu) ?\\.?(feet|foot|ft)\\.?\", r\"\\1cuft \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(cubic|cu)\\.?\", r\"\\1cu \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1gal \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1oz \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1cm \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1mm \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(deg|degrees|degree)\\.?\", r\"\\1deg \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(volts|volt|v)\\.?\", r\"\\1volt \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(watts|watt|w)\\.?\", r\"\\1watt \", s)\n",
    "    s = re.sub(r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1amp \", s)\n",
    "\n",
    "    s = re.sub(r'depot.com/search=', '', s)\n",
    "    s = re.sub(r'pilers,needlenose', 'pliers, needle nose', s)    \n",
    "    \n",
    "    s=s.replace(\"ttt\",\"tt\")    \n",
    "    s=s.replace(\"lll\",\"ll\") \n",
    "    s=s.replace(\"nnn\",\"nn\") \n",
    "    s=s.replace(\"rrr\",\"rr\") \n",
    "    s=s.replace(\"sss\",\"ss\") \n",
    "    s=s.replace(\"zzz\",\"zz\")\n",
    "    s=s.replace(\"ccc\",\"cc\")\n",
    "    s=s.replace(\"eee\",\"ee\")\n",
    "    \n",
    "    s=s.replace(\"acccessories\",\"accessories\")\n",
    "    s=re.sub(r'\\bscott\\b', 'scotts', s) #brand\n",
    "    s=re.sub(r'\\borgainzer\\b', 'organizer', s)\n",
    "    s=re.sub(r'\\bshark bite\\b', 'sharkbite',s)\n",
    "    \n",
    "    s=s.replace(\"hinges with pishinges with pins\",\"hinges with pins\")    \n",
    "    s=s.replace(\"virtue usa\",\"virtu usa\")\n",
    "    s=re.sub('outdoor(?=[a-rt-z])', 'outdoor ', s)\n",
    "    s=re.sub(r'\\bdim able\\b',\"dimmable\", s) \n",
    "    s=re.sub(r'\\blink able\\b',\"linkable\", s)\n",
    "    s=re.sub(r'\\bm aple\\b',\"maple\", s)\n",
    "    s=s.replace(\"aire acondicionado\", \"air conditioner\")\n",
    "    s=s.replace(\"borsh in dishwasher\", \"bosch dishwasher\")\n",
    "    s=re.sub(r'\\bapt size\\b','appartment size', s)\n",
    "    s=re.sub(r'\\barm[e|o]r max\\b','armormax', s)\n",
    "    s=re.sub(r' ss ',' stainless steel ', s)\n",
    "    s=re.sub(r'\\bmay tag\\b','maytag', s)\n",
    "    s=re.sub(r'\\bback blash\\b','backsplash', s)\n",
    "    s=re.sub(r'\\bbum boo\\b','bamboo', s)\n",
    "    s=re.sub(r'(?<=[0-9] )but\\b','btu', s)\n",
    "    s=re.sub(r'\\bcharbroi l\\b','charbroil', s)\n",
    "    s=re.sub(r'\\bair cond[it]*\\b','air conditioner', s)\n",
    "    s=re.sub(r'\\bscrew conn\\b','screw connector', s)\n",
    "    s=re.sub(r'\\bblack decker\\b','black and decker', s)\n",
    "    s=re.sub(r'\\bchristmas din\\b','christmas dinosaur', s)\n",
    "    s=re.sub(r'\\bdoug fir\\b','douglas fir', s)\n",
    "    s=re.sub(r'\\belephant ear\\b','elephant ears', s)\n",
    "    s=re.sub(r'\\bt emp gauge\\b','temperature gauge', s)\n",
    "    s=re.sub(r'\\bsika felx\\b','sikaflex', s)\n",
    "    s=re.sub(r'\\bsquare d\\b', 'squared', s)\n",
    "    s=re.sub(r'\\bbehring\\b', 'behr', s)\n",
    "    s=re.sub(r'\\bcam\\b', 'camera', s)\n",
    "    s=re.sub(r'\\bjuke box\\b', 'jukebox', s)\n",
    "    s=re.sub(r'\\brust o leum\\b', 'rust oleum', s)\n",
    "    s=re.sub(r'\\bx mas\\b', 'christmas', s)\n",
    "    s=re.sub(r'\\bmeld wen\\b', 'jeld wen', s)\n",
    "    s=re.sub(r'\\bg e\\b', 'ge', s)\n",
    "    s=re.sub(r'\\bmirr edge\\b', 'mirredge', s)\n",
    "    s=re.sub(r'\\bx ontrol\\b', 'control', s)\n",
    "    s=re.sub(r'\\boutler s\\b', 'outlets', s)\n",
    "    s=re.sub(r'\\bpeep hole', 'peephole', s)\n",
    "    s=re.sub(r'\\bwater pik\\b', 'waterpik', s)\n",
    "    s=re.sub(r'\\bwaterpi k\\b', 'waterpik', s)\n",
    "    s=re.sub(r'\\bplex[iy] glass\\b', 'plexiglass', s)\n",
    "    s=re.sub(r'\\bsheet rock\\b', 'sheetrock',s)\n",
    "    s=re.sub(r'\\bgen purp\\b', 'general purpose',s)\n",
    "    s=re.sub(r'\\bquicker crete\\b', 'quikrete',s)\n",
    "    s=re.sub(r'\\bref ridge\\b', 'refrigerator',s)\n",
    "    s=re.sub(r'\\bshark bite\\b', 'sharkbite',s)\n",
    "    s=re.sub(r'\\buni door\\b', 'unidoor',s)\n",
    "    s=re.sub(r'\\bair tit\\b','airtight', s)\n",
    "    s=re.sub(r'\\bde walt\\b','dewalt', s)\n",
    "    s=re.sub(r'\\bwaterpi k\\b','waterpik', s)\n",
    "    s=re.sub(r'\\bsaw za(ll|w)\\b','sawzall', s)\n",
    "    s=re.sub(r'\\blg elec\\b', 'lg', s)\n",
    "    s=re.sub(r'\\bhumming bird\\b', 'hummingbird', s)\n",
    "    s=re.sub(r'\\bde ice(?=r|\\b)', 'deice',s)  \n",
    "    s=re.sub(r'\\bliquid nail\\b', 'liquid nails', s)  \n",
    "    s=re.sub(r'\\bdeck over\\b','deckover', s)\n",
    "    s=re.sub(r'\\bcounter sink(?=s|\\b)','countersink', s)\n",
    "    s=re.sub(r'\\bpipes line(?=s|\\b)','pipeline', s)\n",
    "    s=re.sub(r'\\bbook case(?=s|\\b)','bookcase', s)\n",
    "    s=re.sub(r'\\bwalkie talkie\\b','2 pair radio', s)\n",
    "    s=re.sub(r'(?<=^)ks\\b', 'kwikset',s)\n",
    "\n",
    "    \n",
    "    s=re.sub(r'(?<=[1-9]) pac\\b', 'pack', s)\n",
    " \n",
    "    s=re.sub(r'\\bcfl bulbs\\b', 'cfl light bulbs', s)\n",
    "    s=re.sub(r' cfl(?=$)', ' cfl light bulb', s)\n",
    "    s=re.sub(r'candelabra cfl 4 pack', 'candelabra cfl light bulb 4 pack', s)\n",
    "    s=re.sub(r'\\bthhn(?=$|\\ [0-9]|\\ [a-rtuvx-z])', 'thhn wire', s)\n",
    "    s=re.sub(r'\\bplay ground\\b', 'playground',s)\n",
    "    s=re.sub(r'\\bemt\\b', 'emt electrical metallic tube',s)\n",
    "    s=re.sub(r'\\boutdoor dining se\\b', 'outdoor dining set',s)    \n",
    "\n",
    "    s = s.replace(\" x \", \" xby \")\n",
    "    s = s.replace(\"*\", \" xby \")\n",
    "    s = s.replace(\" by \", \" xby\")\n",
    "    s = s.replace(\"x0\", \" xby 0\")\n",
    "    s = s.replace(\"x1\", \" xby 1\")\n",
    "    s = s.replace(\"x2\", \" xby 2\")\n",
    "    s = s.replace(\"x3\", \" xby 3\")\n",
    "    s = s.replace(\"x4\", \" xby 4\")\n",
    "    s = s.replace(\"x5\", \" xby 5\")\n",
    "    s = s.replace(\"x6\", \" xby 6\")\n",
    "    s = s.replace(\"x7\", \" xby 7\")\n",
    "    s = s.replace(\"x8\", \" xby 8\")\n",
    "    s = s.replace(\"x9\", \" xby 9\")\n",
    "    s = s.replace(\"0x\", \"0 xby \")\n",
    "    s = s.replace(\"1x\", \"1 xby \")\n",
    "    s = s.replace(\"2x\", \"2 xby \")\n",
    "    s = s.replace(\"3x\", \"3 xby \")\n",
    "    s = s.replace(\"4x\", \"4 xby \")\n",
    "    s = s.replace(\"5x\", \"5 xby \")\n",
    "    s = s.replace(\"6x\", \"6 xby \")\n",
    "    s = s.replace(\"7x\", \"7 xby \")\n",
    "    s = s.replace(\"8x\", \"8 xby \")\n",
    "    s = s.replace(\"9x\", \"9 xby \")\n",
    "\n",
    "    s = s.replace(\"&\",\" \")\n",
    "    s = s.replace(\"'\",\" \")\n",
    "    s = s.replace(\"  \",\" \")\n",
    "    s = s.replace(\" . \",\" \")\n",
    "\n",
    "    s = unidecode(s.lower())\n",
    "    \n",
    "    for orig, repl in multiword_corrections:\n",
    "        s = s.replace(orig, repl)\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    \n",
    "    for z in s.split(\" \"):\n",
    "        z = z.strip()\n",
    "        if not z:\n",
    "            continue\n",
    "        if z in stopwords:\n",
    "            continue\n",
    "\n",
    "        if z in corrections:\n",
    "            result.extend(corrections[z])\n",
    "        else:\n",
    "            result.append(z)\n",
    "\n",
    "    return [stemmer.stem(z) for z in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "pool = Pool(processes=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_parallel(pool, series, function):\n",
    "    return pool.map(function, series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 330.59844s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "df_all['search_term'] = process_parallel(pool, df_all['search_term'], str_stem)\n",
    "df_products['product_title'] = process_parallel(pool, df_products['product_title'], str_stem)\n",
    "df_products['product_description'] = process_parallel(pool, df_products['product_description'], str_stem)\n",
    "df_attr['value'] = process_parallel(pool, df_attr['value'], str_stem)\n",
    "\n",
    "print 'took %0.5fs.' % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2534419"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = []\n",
    "\n",
    "df_all['search_term'].apply(all_text.append)\n",
    "df_products['product_title'].apply(all_text.append)\n",
    "df_products['product_description'].apply(all_text.append)\n",
    "df_attr['value'].apply(all_text.append)\n",
    "\n",
    "len(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "num_features = 300    # Word vector dimensionality\n",
    "min_word_count = 10   # Minimum word count\n",
    "num_workers = 8     # Number of threads to run in parallel\n",
    "context = 3          # Context window size\n",
    "downsampling = 1e-3   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 109.76043s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "model = Word2Vec(all_text, workers=num_workers, size=num_features, min_count=min_word_count,\n",
    "                 window=context, sample=downsampling, seed=1)\n",
    "\n",
    "print 'took %0.5fs.' % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('home_depot_w2v_clean.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
