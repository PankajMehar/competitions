{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, label_binarize\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, NMF, TruncatedSVD\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libscores import pac_metric\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_info(file_name):\n",
    "    result = []\n",
    "    \n",
    "    for line in file(file_name):\n",
    "        key, value = line.strip().split('=')\n",
    "        key = key.strip()\n",
    "        value = value.strip().strip(\"'\")\n",
    "        if value.isdigit():\n",
    "            value = int(value)\n",
    "        result.append((key, value))\n",
    "    \n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feat_num': 47236,\n",
       " 'feat_type': 'Numerical',\n",
       " 'has_categorical': 0,\n",
       " 'has_missing': 0,\n",
       " 'is_sparse': 1,\n",
       " 'label_num': 95,\n",
       " 'metric': 'pac_metric',\n",
       " 'name': 'tania',\n",
       " 'target_num': 95,\n",
       " 'target_type': 'Binary',\n",
       " 'task': 'multilabel.classification',\n",
       " 'test_num': 44635,\n",
       " 'time_budget': 1200,\n",
       " 'train_num': 157599,\n",
       " 'usage': 'AutoML challenge 2014',\n",
       " 'valid_num': 22514}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public = read_info('data/set4_tania/tania_public.info')\n",
    "public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = public['feat_num']\n",
    "\n",
    "def read_sparse_features(fine_name):\n",
    "    result = list()\n",
    "    for line in file(fine_name):\n",
    "        row = []\n",
    "        for el in line.strip().split(' '): \n",
    "            pos, value = el.split(':')\n",
    "            pos = int(pos) - 1\n",
    "            row.append((pos, float(value)))\n",
    "        result.append(row)\n",
    "\n",
    "    rnum = len(result)\n",
    "    X = scipy.sparse.dok_matrix((rnum, dim), dtype=np.float)\n",
    "    for idx, row in enumerate(result):\n",
    "        for pos, val in row:\n",
    "            X[idx, pos] = val\n",
    "\n",
    "    return scipy.sparse.csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_multilabels(file_name):\n",
    "    result = list()\n",
    "    for line in file(file_name):\n",
    "        row = [f for f in line.strip().split(' ')]\n",
    "        result.append(row.index('1'))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, X_valid, X_test = pickle.load(open('data/set4_tania/data.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "X = read_sparse_features('data/set4_tania/tania_train.data')\n",
    "y = read_multilabels('data/set4_tania/tania_train.solution')\n",
    "\n",
    "X_valid = read_sparse_features('data/set4_tania/tania_valid.data')\n",
    "X_test  = read_sparse_features('data/set4_tania/tania_test.data')\n",
    "\n",
    "print X.shape, y.shape, np.unique(y).shape\n",
    "print X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle.dump([X, y, X_valid, X_test], open('data/set4_tania/data.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows, cols = X.nonzero()\n",
    "per_col_count = np.bincount(cols)\n",
    "\n",
    "X = X[:, per_col_count > 5]\n",
    "X_valid = X_valid[:, per_col_count > 5]\n",
    "X_test = X_test[:, per_col_count > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False, copy=False)\n",
    "X = scaler.fit_transform(X)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [01:03<01:49, 15.71s/it]"
     ]
    }
   ],
   "source": [
    "n_iter = 5\n",
    "cv = StratifiedShuffleSplit(y, n_iter=n_iter, test_size=0.25, random_state=1)\n",
    "\n",
    "scores = []\n",
    "it = 1\n",
    "for train, test in cv:\n",
    "    print 'iteration %d' % it\n",
    "\n",
    "    model = LogisticRegression(n_jobs=-1, penalty='l1', C=0.01)\n",
    "    \n",
    "    X_train = X[train]\n",
    "    y_train = y[train]\n",
    "    N, d = X_train.shape\n",
    "\n",
    "    sample_size = list(range(10000, N, 10000))\n",
    "    for j in tqdm(sample_size):\n",
    "        X_sample, _, y_sample, _ = \\\n",
    "            train_test_split(X_train, y_train, train_size=j, random_state=1, stratify=y_train)\n",
    "        model.fit(X_sample, y_sample)\n",
    "        y_pred = model.predict_proba(X[test])\n",
    "\n",
    "        score = pac_metric(label_binarize(y[test], classes=classes), y_pred)\n",
    "        scores.append((it, j, score))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X[test])\n",
    "    score = pac_metric(label_binarize(y[test], classes=classes), y_pred)\n",
    "    scores.append((it, N, score))\n",
    "\n",
    "    it = it + 1\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c0c08df98240>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearning\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'learning' is not defined"
     ]
    }
   ],
   "source": [
    "learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1, 5), indices imply (3, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1ff9ad525dde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'it'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sample_size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlearning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'it'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/agrigorev/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m                     mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 281\u001b[1;33m                                              copy=copy)\n\u001b[0m\u001b[0;32m    282\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/agrigorev/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_init_ndarray\u001b[1;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_possibly_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/agrigorev/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   3903\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'values'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3904\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3905\u001b[1;33m         \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3907\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/agrigorev/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mconstruction_error\u001b[1;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[0;32m   3880\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3881\u001b[0m     raise ValueError(\"Shape of passed values is {0}, indices imply {1}\".format(\n\u001b[1;32m-> 3882\u001b[1;33m         passed,implied))\n\u001b[0m\u001b[0;32m   3883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (1, 5), indices imply (3, 5)"
     ]
    }
   ],
   "source": [
    "learning = pd.DataFrame(scores, columns=['it', 'sample_size', 'score'])\n",
    "\n",
    "for it, grp in learning.groupby('it'):\n",
    "    plt.plot(grp.sample_size, grp.score)\n",
    "\n",
    "mean_score = learning.groupby('sample_size').score.mean()\n",
    "plt.plot(mean_score.index, mean_score.values, color='black', linewidth=2)\n",
    "\n",
    "plt.title('Learning curves')\n",
    "plt.xlabel('Sample size')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.327397312688 0.0\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'logreg': LogisticRegression(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'cv_train_size': 8000,\n",
    "    'model': 'logreg'\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', models[params['model']])\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'model__penalty': 'l1',\n",
    "    'model__C': 5,\n",
    "}\n",
    "pipeline.set_params(**pipe_params)\n",
    "\n",
    "n_iter = 5\n",
    "cv = StratifiedShuffleSplit(y, n_iter=n_iter, train_size=params['cv_train_size'], random_state=1)\n",
    "\n",
    "scores = []\n",
    "for train, test in tqdm(cv):\n",
    "    pipeline.fit(X_input[train], y[train])\n",
    "    y_pred = pipeline.predict_proba(X_input[test])\n",
    "    score = pac_metric(label_binarize(y[test], classes=classes), y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "params.update(pipe_params)\n",
    "results.append((params, np.mean(score), np.std(score)))\n",
    "print np.mean(score), np.std(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.32740 ± 0.00000, params: {'model__C': 5, 'model': 'logreg', 'model__penalty': 'l1', 'cv_train_size': 8000}\n",
      "score: 0.28432 ± 0.00000, params: {'model__C': 10, 'model': 'logreg', 'model__penalty': 'l1', 'cv_train_size': 8000}\n",
      "score: 0.43695 ± 0.00000, params: {'model__C': 1, 'model': 'logreg', 'model__penalty': 'l1', 'cv_train_size': 8000}\n",
      "score: 0.32191 ± 0.00000, params: {'model__C': 0.01, 'model': 'logreg', 'model__penalty': 'l1', 'cv_train_size': 8000}\n"
     ]
    }
   ],
   "source": [
    "for p, s, std in reversed(results[-5:]):\n",
    "    print u'score: %0.5f ± %0.5f, params: %s' % (s, std, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_valid_score = pipeline.predict_proba(X_valid)[:, 1]\n",
    "y_test_score = pipeline.predict_proba(X_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('submission/helena_valid.predict', y_valid_score, fmt='%0.18f')\n",
    "np.savetxt('submission/helena_test.predict', y_test_score, fmt='%0.18f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
