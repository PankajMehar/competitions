{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_json('data/train.json')\n",
    "df_test = pd.read_json('data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       34284\n",
       "medium    11229\n",
       "high       3839\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.interest_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interest_level_map = {'low': 0, 'medium': 1, 'high': 2}\n",
    "df_train.interest_level = df_train.interest_level.apply(lambda x: interest_level_map.get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_path_full(url):\n",
    "    path = url[url.rfind('/')+1:]\n",
    "    return '/' + path[0:7] + '/' + path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "folds = np.random.choice([0, 1, 2, 3, 4, 5], size=len(df_train))\n",
    "df_train['fold'] = folds.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_train = []\n",
    "\n",
    "for row in df_train.itertuples():\n",
    "    id = row.listing_id\n",
    "    fold = row.fold\n",
    "    lev = row.interest_level\n",
    "    for p in row.photos:\n",
    "        path = image_path_full(p)\n",
    "        images_train.append((id, path, lev, fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>image</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>274272</th>\n",
       "      <td>6825469</td>\n",
       "      <td>/6825469/6825469_821bbf62fe3aa31d02c280e32699f...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156522</th>\n",
       "      <td>7075598</td>\n",
       "      <td>/7075598/7075598_f0d4610b19b77bfba1a9aabb46992...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90125</th>\n",
       "      <td>7116399</td>\n",
       "      <td>/7116399/7116399_a7de1b4810c351badb6a3a77a5578...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146039</th>\n",
       "      <td>7008495</td>\n",
       "      <td>/7008495/7008495_137a6915dd2a7688423cba6f2f87f...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98000</th>\n",
       "      <td>7230905</td>\n",
       "      <td>/7230905/7230905_34ca4dff89629bd3aa25e7016287a...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        listing_id                                              image  \\\n",
       "274272     6825469  /6825469/6825469_821bbf62fe3aa31d02c280e32699f...   \n",
       "156522     7075598  /7075598/7075598_f0d4610b19b77bfba1a9aabb46992...   \n",
       "90125      7116399  /7116399/7116399_a7de1b4810c351badb6a3a77a5578...   \n",
       "146039     7008495  /7008495/7008495_137a6915dd2a7688423cba6f2f87f...   \n",
       "98000      7230905  /7230905/7230905_34ca4dff89629bd3aa25e7016287a...   \n",
       "\n",
       "        interest_level  fold  \n",
       "274272               0     2  \n",
       "156522               1     2  \n",
       "90125                2     2  \n",
       "146039               0     3  \n",
       "98000                0     4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images_train = pd.DataFrame(images_train, columns=['listing_id', 'image', 'interest_level', 'fold'])\n",
    "df_images_train.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from keras.applications.inception_v3 import InceptionV3\n",
    "#from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "#from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(impath):\n",
    "    if not os.path.exists(impath):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        #img = image.load_img(impath, target_size=(224, 224))\n",
    "        img = image.load_img(impath, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        return preprocess_input(x)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276714/276714 [25:28<00:00, 181.04it/s] | 7/276714 [00:00<1:07:40, 68.14it/s] 77%|███████▋  | 212290/276714 [20:46<06:18, 170.28it/s]\n"
     ]
    }
   ],
   "source": [
    "failures = []\n",
    "\n",
    "for impath in tqdm(df_images_train.image):\n",
    "    new_path = 'processed_vgg' + impath + '.npy'\n",
    "    if os.path.exists(new_path):\n",
    "        continue\n",
    "\n",
    "    img = load_img('images' + impath)\n",
    "    if img is None:\n",
    "        failures.append(impath)\n",
    "        continue    \n",
    "\n",
    "    folder = os.path.dirname(new_path)\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "\n",
    "    np.save(new_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot serialize column 1 named image with dtype empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-96a1d28661d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfailures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_images_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_images_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf_images_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_images_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tmp/df_images_train.feather'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/feather/api.py\u001b[0m in \u001b[0;36mwrite_dataframe\u001b[0;34m(df, path)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0minferred_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'unicode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'string'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot serialize column 1 named image with dtype empty"
     ]
    }
   ],
   "source": [
    "failures = set(failures)\n",
    "df_images_train = df_images_train[~df_images_train.image.isin(failures)]\n",
    "feather.write_dataframe(df_images_train, 'tmp/df_images_train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_images_train = feather.read_dataframe('tmp/df_images_train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fold012 = df_images_train[df_images_train.fold.isin([0, 1, 2])].reset_index(drop=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_proto = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_batches(df, n):\n",
    "    for i in range(0, len(df), n):\n",
    "        yield df.iloc[i:i+n]\n",
    "\n",
    "def df_image_generator(df, n=32, seed=0):\n",
    "    i = 0\n",
    "    while True:\n",
    "        df = shuffle(df, random_state=(seed + i))\n",
    "\n",
    "        batches = prepare_batches(df, n)\n",
    "\n",
    "        for batch in batches:\n",
    "            batch_res = []\n",
    "            batch_label = []\n",
    "\n",
    "            for impath, label in zip(batch.image, batch.interest_level):\n",
    "                path = 'processed_vgg' + impath + '.npy'\n",
    "\n",
    "                if not os.path.exists(path):\n",
    "                    continue\n",
    "\n",
    "                batch_res.append(np.load(path))\n",
    "                batch_label.append(y_proto[label])\n",
    "\n",
    "            if len(batch_res) > 0:\n",
    "                batch_res = np.array(batch_res)\n",
    "                batch_label = np.array(batch_label)\n",
    "                yield batch_res, batch_label\n",
    "\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4298"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "steps = ceil(len(fold012) / 32)\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen = df_image_generator(fold012, n=32, seed=1)\n",
    "\n",
    "model.fit_generator(gen, steps_per_epoch=steps, epochs=10, \n",
    "                    verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45735/45735 [01:11<00:00, 642.02it/s]  | 52/45735 [00:00<01:27, 519.86it/s]\n"
     ]
    }
   ],
   "source": [
    "fold3 = df_images_train[df_images_train.fold == 3].reset_index(drop=1)\n",
    "\n",
    "val_imgs = []\n",
    "\n",
    "for impath in tqdm(fold3.image):\n",
    "    path = 'processed' + impath + '.npy'\n",
    "    val_imgs.append(np.load(path))\n",
    "\n",
    "val_imgs = np.array(val_imgs)\n",
    "y_val = y_proto[fold3.interest_level.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(val_imgs)\n",
    "log_loss(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "18b47c472b9647468b1d8336085c3a1e": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "2e0241677acd409199d3051fb34fbdcd": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "76c17bd155e847cd8a5015e216cad935": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "778eaceb572a4f26a2a315cad13c8772": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "8ca484122d204da6849f17b95ac5a6a2": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "a6eaaf3eb93d44b29271338cae8818ba": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "b1423c632782479bae9342520f3de05b": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "bfee9193cb1f4343862d383aa5d89072": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "da50bc388a614b86ae8e1bf7ad08bf5a": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "fe3d78fac59149289f74c59db5355877": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
