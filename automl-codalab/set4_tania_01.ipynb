{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, label_binarize\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, NMF, TruncatedSVD\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit, ShuffleSplit\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from libscores import pac_metric\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_info(file_name):\n",
    "    result = []\n",
    "    \n",
    "    for line in file(file_name):\n",
    "        key, value = line.strip().split('=')\n",
    "        key = key.strip()\n",
    "        value = value.strip().strip(\"'\")\n",
    "        if value.isdigit():\n",
    "            value = int(value)\n",
    "        result.append((key, value))\n",
    "    \n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feat_num': 47236,\n",
       " 'feat_type': 'Numerical',\n",
       " 'has_categorical': 0,\n",
       " 'has_missing': 0,\n",
       " 'is_sparse': 1,\n",
       " 'label_num': 95,\n",
       " 'metric': 'pac_metric',\n",
       " 'name': 'tania',\n",
       " 'target_num': 95,\n",
       " 'target_type': 'Binary',\n",
       " 'task': 'multilabel.classification',\n",
       " 'test_num': 44635,\n",
       " 'time_budget': 1200,\n",
       " 'train_num': 157599,\n",
       " 'usage': 'AutoML challenge 2014',\n",
       " 'valid_num': 22514}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public = read_info('data/set4_tania/tania_public.info')\n",
    "public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = public['feat_num']\n",
    "\n",
    "def read_sparse_features(fine_name):\n",
    "    result = list()\n",
    "    for line in file(fine_name):\n",
    "        row = []\n",
    "        for el in line.strip().split(' '): \n",
    "            pos, value = el.split(':')\n",
    "            pos = int(pos) - 1\n",
    "            row.append((pos, float(value)))\n",
    "        result.append(row)\n",
    "\n",
    "    rnum = len(result)\n",
    "    X = scipy.sparse.dok_matrix((rnum, dim), dtype=np.float)\n",
    "    for idx, row in enumerate(result):\n",
    "        for pos, val in row:\n",
    "            X[idx, pos] = val\n",
    "\n",
    "    return scipy.sparse.csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_multilabels(file_name):\n",
    "    result = list()\n",
    "    for line in file(file_name):\n",
    "        row = [int(f) for f in line.strip().split(' ')]\n",
    "        result.append(row)\n",
    "    return scipy.sparse.csr_matrix(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, X_valid, X_test = pickle.load(open('data/set4_tania/data.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "X = read_sparse_features('data/set4_tania/tania_train.data')\n",
    "y = read_multilabels('data/set4_tania/tania_train.solution')\n",
    "\n",
    "X_valid = read_sparse_features('data/set4_tania/tania_valid.data')\n",
    "X_test  = read_sparse_features('data/set4_tania/tania_test.data')\n",
    "\n",
    "print X.shape, y.shape, np.unique(y).shape\n",
    "print X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pickle.dump([X, y, X_valid, X_test], open('data/set4_tania/data.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows, cols = X.nonzero()\n",
    "per_col_count = np.bincount(cols)\n",
    "\n",
    "X = X[:, per_col_count > 5]\n",
    "X_valid = X_valid[:, per_col_count > 5]\n",
    "X_test = X_test[:, per_col_count > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean=False, copy=False)\n",
    "X = scaler.fit_transform(X)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_input = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def column(y, n):\n",
    "    return y[:, n].toarray().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.59379\n",
      "iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.59561\n",
      "iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.59554\n",
      "iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.60041\n",
      "iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.59904\n",
      "0.596877948831 0.0024538743718\n"
     ]
    }
   ],
   "source": [
    "base_model = LogisticRegression(penalty='l1', C=0.03)\n",
    "\n",
    "n_iter = 5\n",
    "n, y_dim = y.shape\n",
    "cv = ShuffleSplit(n, n_iter=n_iter, train_size=15000, random_state=1)\n",
    "\n",
    "scores = []\n",
    "for iter_no, (train, test) in enumerate(cv):\n",
    "    print 'iteration %d' % iter_no\n",
    "\n",
    "    y_pred = np.zeros(y[test].shape)\n",
    "    for i in tqdm(range(y_dim)):\n",
    "        y_i = column(y[train], i)\n",
    "        base_model.fit(X_input[train], y_i)    \n",
    "        y_pred[:, i] = base_model.predict_proba(X_input[test])[:, 1]\n",
    "\n",
    "    score = pac_metric(y[test].toarray(), y_pred, task='multilabel.classification')\n",
    "    print 'score %0.5f' % score\n",
    "    scores.append(score)\n",
    "\n",
    "print np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "y_test_pred = np.zeros((X_test.shape[0], y_dim))\n",
    "y_valid_pred = np.zeros((X_valid.shape[0], y_dim))\n",
    "\n",
    "for i in tqdm(range(y_dim)):\n",
    "    y_i = column(y, i)\n",
    "    base_model.fit(X_input, y_i)    \n",
    "    y_test_pred[:, i] = base_model.predict_proba(X_test)[:, 1]\n",
    "    y_valid_pred[:, i] = base_model.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('submission/tania_valid.predict', y_valid_pred, fmt='%0.10f')\n",
    "np.savetxt('submission/tania_test.predict', y_test_pred, fmt='%0.10f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
