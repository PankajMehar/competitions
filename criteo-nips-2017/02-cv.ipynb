{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input = gzip.open('data/criteo_train.txt.gz', 'r')\n",
    "\n",
    "files = [\n",
    "    open('data/train_0.txt', 'w'),\n",
    "    open('data/train_1.txt', 'w'),\n",
    "    open('data/train_2.txt', 'w'),\n",
    "    open('data/train_3.txt', 'w'),\n",
    "]\n",
    "\n",
    "for line in tqdm(train_input):\n",
    "    line = line.decode()\n",
    "    split = line.split('|')\n",
    "    id = int(split[0].strip())\n",
    "    fold = hash(id) % 4\n",
    "    files[fold].write(line)\n",
    "\n",
    "for f in files:\n",
    "    f.flush()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "173979748it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Line = namedtuple('Line', ['id', 'f0', 'f1', 'idx', 'val'])\n",
    "LabeledLine = namedtuple('LabeledLine', ['id', 'f0', 'f1', 'idx', 'val', 'propensity', 'label'])\n",
    "\n",
    "def parse_features(s):\n",
    "    split = s.split(' ')\n",
    "    f0 = split[0]\n",
    "    assert f0.startswith('0:')\n",
    "    f0 = int(f0[2:])\n",
    "\n",
    "    f1 = split[1]\n",
    "    assert f1.startswith('1:')\n",
    "    f1 = int(f1[2:])\n",
    "\n",
    "    idx = []\n",
    "    values = []\n",
    "    \n",
    "    for fv in split[2:]:\n",
    "        f, v = fv.split(':')\n",
    "        idx.append(int(f) - 2)\n",
    "        values.append(int(v))\n",
    "\n",
    "    return f0, f1, idx, values\n",
    "\n",
    "def read_train(fname):\n",
    "    if fname.endswith('.gz'):\n",
    "        f = gzip.open(fname, 'r')\n",
    "        f = map(bytes.decode, f)\n",
    "    else:\n",
    "        f = open(fname, 'r')\n",
    "\n",
    "    for line in f:\n",
    "        split = line.split('|')\n",
    "        id = int(split[0].strip())\n",
    "\n",
    "        label = None\n",
    "        propensity = None\n",
    "        features = None\n",
    "\n",
    "        if len(split) == 4:\n",
    "            l = split[1]\n",
    "            assert l.startswith('l')\n",
    "\n",
    "            l = l.lstrip('l ').strip()\n",
    "            if l == '0.999':\n",
    "                label = 0\n",
    "            elif l == '0.001':\n",
    "                label = 1\n",
    "            else:\n",
    "                raise Exception('ololo')\n",
    "\n",
    "            p = split[2]\n",
    "            assert p.startswith('p')\n",
    "            p = p.lstrip('p ').strip()\n",
    "            propensity = float(p)\n",
    "\n",
    "            features = split[3].lstrip('f ').strip()\n",
    "\n",
    "            f0, f1, idx, val = parse_features(features)\n",
    "            idx = np.array(idx, dtype=np.uint32)\n",
    "            val = np.array(val, dtype=np.uint8)\n",
    "            yield LabeledLine(id, f0, f1, idx, val, propensity, label)\n",
    "        elif len(split) == 2:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "it0 = read_train('data/train_0.txt')\n",
    "it1 = read_train('data/train_1.txt')\n",
    "it2 = read_train('data/train_2.txt')\n",
    "it_train = itertools.chain(it0, it1, it2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = []\n",
    "\n",
    "for line in tqdm(it_train):\n",
    "    df_train.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tmp/df_train.bin', 'wb') as f:\n",
    "    pickle.dump(df_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it_val = read_train('data/train_3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_val = []\n",
    "\n",
    "for line in tqdm(it_val):\n",
    "    df_val.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_val = pd.DataFrame(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tmp/df_val.bin', 'wb') as f:\n",
    "    pickle.dump(df_val, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tmp/df_train.bin', 'rb') as f:\n",
    "    df_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('tmp/df_val.bin', 'rb') as f:\n",
    "    df_val = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_csr(cols, vals, shape=74000):\n",
    "    lens = [len(c) for c in cols]\n",
    "    intptr = np.zeros((len(cols) + 1), dtype='uint32')\n",
    "    intptr[1:] = lens\n",
    "    intptr = intptr.cumsum()\n",
    "\n",
    "    columns = np.concatenate(cols).astype('uint32')\n",
    "    values = np.concatenate(vals).astype('uint8')\n",
    "\n",
    "    return sp.csr_matrix((values, columns, intptr), shape=(len(cols), shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = to_csr(list(df_train.idx), list(df_train.val))\n",
    "X_val = to_csr(list(df_val.idx), list(df_val.val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sp.save_npz('tmp/X_train_sparse.npz', X_train, compressed=False)\n",
    "sp.save_npz('tmp/X_val_sparse.npz', X_val, compressed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train.label.values.astype('uint8')\n",
    "y_val = df_val.label.values.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prospensity_val = df_val.propensity.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_num_train = df_train[['f0', 'f1']].values.astype('uint16')\n",
    "X_num_val = df_val[['f0', 'f1']].values.astype('uint16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('tmp/y_train.npy', y_train)\n",
    "np.save('tmp/y_val.npy', y_val)\n",
    "\n",
    "np.save('tmp/X_num_train.npy', X_num_train)\n",
    "np.save('tmp/X_num_val.npy', X_num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('tmp/prospensity_val.npy', prospensity_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = sp.load_npz('tmp/X_train_sparse.npz')\n",
    "X_val = sp.load_npz('tmp/X_val_sparse.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.load('tmp/y_train.npy', )\n",
    "y_val = np.load('tmp/y_val.npy', )\n",
    "\n",
    "X_num_train = np.load('tmp/X_num_train.npy', )\n",
    "X_num_val = np.load('tmp/X_num_val.npy', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt = (X_train > 0).sum(axis=0)\n",
    "cnt = np.asarray(cnt)[0]\n",
    "mask = cnt >= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53309459459459463"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cnt >= 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_f = X_train[:, mask]\n",
    "X_val_f = X_val[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<10631142x39449 sparse matrix of type '<class 'numpy.uint8'>'\n",
       " \twith 261790690 stored elements in Compressed Sparse Row format>,\n",
       " <3544334x39449 sparse matrix of type '<class 'numpy.uint8'>'\n",
       " \twith 87299061 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_f, X_val_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = open('exp.log', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.05, took 7730.881s, auc=0.731\n",
      "C=0.1, took 7685.568s, auc=0.733\n",
      "C=0.5, took 10003.983s, auc=0.734\n",
      "C=1, took 9697.831s, auc=0.733\n"
     ]
    }
   ],
   "source": [
    "for C in [0.05, 0.1, 0.5, 1]:\n",
    "    t0 = time()\n",
    "\n",
    "    lr = LogisticRegression(penalty='l1', C=C, random_state=1)\n",
    "    lr.fit(X_train_f, y_train)\n",
    "\n",
    "    y_pred = lr.decision_function(X_val_f)\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "    print('C=%s, took %.3fs, auc=%.3f' % (C, time() - t0, auc))\n",
    "    log.write('C=%s, took %.3fs, auc=%.3f' % (C, time() - t0, auc))\n",
    "    log.write('\\n')\n",
    "    log.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log.flush()\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
