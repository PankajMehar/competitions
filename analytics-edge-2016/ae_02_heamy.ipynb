{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from natsort import natsorted\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "from ml_metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train2016.csv')\n",
    "df_test = pd.read_csv('../input/test2016.csv')\n",
    "\n",
    "party_encoder = LabelEncoder()\n",
    "df_train.Party = party_encoder.fit_transform(df_train.Party)\n",
    "\n",
    "TRAIN = 0\n",
    "HOLD_OUT = 1\n",
    "TEST = 2\n",
    "\n",
    "df_train['source'] = TRAIN\n",
    "cv = StratifiedShuffleSplit(df_train.Party, n_iter=1, test_size=500, random_state=31)\n",
    "_, holdout_idx = next(iter(cv))\n",
    "df_train.loc[holdout_idx, 'source'] = HOLD_OUT\n",
    "df_test['source'] = TEST\n",
    "\n",
    "df_all = pd.concat([df_train, df_test]).reset_index(drop=1)\n",
    "\n",
    "describe = df_all.YOB.describe(percentiles=[0.01, 0.99])\n",
    "low = describe['1%']\n",
    "high = describe['99%']\n",
    "\n",
    "df_all.loc[(df_all.YOB < low) | (df_all.YOB > high), 'YOB'] = np.nan \n",
    "\n",
    "# age brackets: below 20 - 20-29 - 30-39 - 40-49 - 50-59 - 60+\n",
    "age = 2016 - df_all.YOB\n",
    "\n",
    "bins = [0, 19, 29, 39, 49, 59, 100]\n",
    "labels = [('%d-%d') % (bins[i], bins[i + 1]) for i in range(len(bins) - 1)]\n",
    "df_all['Age'] = pd.cut(age, bins=bins, labels=labels).astype(str)\n",
    "df_all.drop('YOB', axis=1, inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_columns  = natsorted(set(df_all.columns) - {'USER_ID', 'Party', 'source'})\n",
    "questions    = [q for q in all_columns if q.startswith('Q')]\n",
    "demographics = ['Age', 'EducationLevel', 'Gender', 'HouseholdStatus', 'Income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in all_columns:\n",
    "    df_all[c] = df_all[c].str.lower()\n",
    "\n",
    "def clean_level_names(s):\n",
    "    if isinstance(s, float):\n",
    "        return s\n",
    "    s = s.replace('$', '')\n",
    "    s = s.replace(',', '')\n",
    "    s = s.replace(' - ', '_')\n",
    "    s = s.replace(' ', '_')\n",
    "    return s\n",
    "\n",
    "df_all.Income = df_all.Income.apply(clean_level_names)\n",
    "df_all.HouseholdStatus = df_all.HouseholdStatus.str.replace(' ', '_')\n",
    "df_all.EducationLevel = df_all.EducationLevel.str.replace(' ', '_')\n",
    "\n",
    "df_all.Q117193 = df_all.Q117193.str.replace(' ', '_')\n",
    "df_all.Q120194 = df_all.Q120194.str.replace(' ', '_')\n",
    "\n",
    "df_all.Q98059  = df_all.Q98059.map({'yes': 'yes', 'only-child': 'no'})\n",
    "df_all.Q99982  = df_all.Q99982.map({'check!': 'yes', 'nope': 'no'})\n",
    "df_all.Q106997 = df_all.Q106997.map({'yay people!': 'yes', 'grrr people': 'no'})\n",
    "df_all.Q108855 = df_all.Q108855.map({'yes!': 'yes', 'umm...': 'no'})\n",
    "df_all.Q117186 = df_all.Q117186.map({'hot headed': 'yes', 'cool headed': 'no'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.loc[:, all_columns] = df_all.loc[:, all_columns].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('questions_selected.csv', index_col='Question ID')\n",
    "yes_no = set(df_questions[df_questions['Possible Answers'] == 'Yes,No'].index) \n",
    "yes_no = natsorted(yes_no | {'Q98059', 'Q99982', 'Q106997', 'Q108855', 'Q117186'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_all[df_all.source == TRAIN]\n",
    "df_holdout = df_all[df_all.source == HOLD_OUT]\n",
    "df_test = df_all[df_all.source == TEST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_questions = [\"Q109244\", \"Q115611\", \"Q98197\", \"Q113181\", \"Q98869\", \"Q99480\", \"Q116881\", \"Q106272\", \"Q115195\"]\n",
    "top = demographics + best_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records = df_all[top].to_dict(orient='records')\n",
    "oh_vectorizer = DictVectorizer(separator='_',)\n",
    "oh_top = oh_vectorizer.fit_transform(records)\n",
    "\n",
    "svd_top_5 = TruncatedSVD(n_components=5, random_state=1).fit_transform(oh_top)\n",
    "svd_top_10 = TruncatedSVD(n_components=10, random_state=1).fit_transform(oh_top)\n",
    "svd_top_15 = TruncatedSVD(n_components=15, random_state=1).fit_transform(oh_top)\n",
    "nmf_top_5 = NMF(n_components=5, random_state=1).fit_transform(oh_top)\n",
    "nmf_top_10 = NMF(n_components=10, random_state=1).fit_transform(oh_top)\n",
    "nmf_top_15 = NMF(n_components=15, random_state=1).fit_transform(oh_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_selected = natsorted(set(all_columns) - set(top))\n",
    "records = df_all[not_selected].to_dict(orient='records')\n",
    "oh_vectorizer = DictVectorizer(separator='_',)\n",
    "oh_not_selected = oh_vectorizer.fit_transform(records)\n",
    "\n",
    "svd_not_selected_10 = TruncatedSVD(n_components=10, random_state=1).fit_transform(oh_not_selected)\n",
    "nmf_not_selected_10 = NMF(n_components=10, random_state=1).fit_transform(oh_not_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records = df_all[all_columns].to_dict(orient='records')\n",
    "oh_vectorizer = DictVectorizer(separator='_',)\n",
    "oh_all = oh_vectorizer.fit_transform(records)\n",
    "\n",
    "svd_all_15 = TruncatedSVD(n_components=15, random_state=1).fit_transform(oh_all)\n",
    "svd_all_25 = TruncatedSVD(n_components=25, random_state=1).fit_transform(oh_all)\n",
    "svd_all_50 = TruncatedSVD(n_components=50, random_state=1).fit_transform(oh_all)\n",
    "nmf_all_15 = NMF(n_components=15, random_state=1).fit_transform(oh_all)\n",
    "nmf_all_25 = NMF(n_components=25, random_state=1).fit_transform(oh_all)\n",
    "nmf_all_50 = NMF(n_components=50, random_state=1).fit_transform(oh_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'oh_top': oh_top.toarray(),\n",
    "    'svd_top_5': svd_top_5,\n",
    "    'svd_top_10': svd_top_10,\n",
    "    'svd_top_15': svd_top_15,\n",
    "    'nmf_top_5': nmf_top_5,\n",
    "    'nmf_top_10': nmf_top_10,\n",
    "    'nmf_top_15': nmf_top_15,\n",
    "    'oh_top_notsel_svd': np.hstack([oh_top.toarray(), svd_not_selected_10]),  \n",
    "    'svd_top_5_notsel_svd': np.hstack([svd_top_5, svd_not_selected_10]),\n",
    "    'svd_top_10_notsel_svd': np.hstack([svd_top_10, svd_not_selected_10]),\n",
    "    'svd_top_15_notsel_svd': np.hstack([svd_top_15, svd_not_selected_10]),\n",
    "    'nmf_top_5_notsel_svd': np.hstack([nmf_top_5, svd_not_selected_10]),\n",
    "    'nmf_top_10_notsel_svd': np.hstack([nmf_top_10, svd_not_selected_10]),\n",
    "    'nmf_top_15_notsel_svd': np.hstack([nmf_top_15, svd_not_selected_10]),\n",
    "    'oh_top_notsel_nmf': np.hstack([oh_top.toarray(), nmf_not_selected_10]),\n",
    "    'svd_top_5_notsel_nmf': np.hstack([svd_top_5, nmf_not_selected_10]),\n",
    "    'svd_top_10_notsel_nmf': np.hstack([svd_top_10, nmf_not_selected_10]),\n",
    "    'svd_top_15_notsel_nmf': np.hstack([svd_top_15, nmf_not_selected_10]),\n",
    "    'nmf_top_5_notsel_nmf': np.hstack([nmf_top_5, nmf_not_selected_10]),\n",
    "    'nmf_top_10_notsel_nmf': np.hstack([nmf_top_10, nmf_not_selected_10]),\n",
    "    'nmf_top_15_notsel_nmf': np.hstack([nmf_top_15, nmf_not_selected_10]),\n",
    "    'oh_all': oh_all.toarray(),\n",
    "    'svd_all_15': svd_all_15,\n",
    "    'svd_all_25': svd_all_25,\n",
    "    'svd_all_50': svd_all_50,\n",
    "    'nmf_all_15': nmf_all_15,\n",
    "    'nmf_all_25': nmf_all_25,\n",
    "    'nmf_all_50': nmf_all_50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "def round_to_int(val_min, val_max):\n",
    "    return ('transform', int, (val_min, val_max))\n",
    "\n",
    "def find_best_params(X, y, model, evaluation_callback, search_space, bo_rounds=20, verbose=0):\n",
    "    cv = StratifiedKFold(y, n_folds=3, shuffle=True, random_state=1)\n",
    "\n",
    "    search_space_internal = {}\n",
    "    to_transform = {}\n",
    "    for k, v in search_space.items():\n",
    "        if v[0] == 'transform':\n",
    "            search_space_internal[k] = v[2]\n",
    "            to_transform[k] = v[1]\n",
    "        else:\n",
    "            search_space_internal[k] = v\n",
    "    \n",
    "    def transform_params(params):\n",
    "        result = {}\n",
    "        for k, v in params.items():\n",
    "            if k in to_transform:\n",
    "                f = to_transform[k]\n",
    "                result[k] = f(v)\n",
    "            else:\n",
    "                result[k] = v\n",
    "        return result\n",
    "    \n",
    "    def optimize(**params):\n",
    "        scores = []\n",
    "        params = transform_params(params)\n",
    "        model.set_params(**params)\n",
    "        for train, test in cv:\n",
    "            model.fit(X[train], y[train])\n",
    "            score = evaluation_callback(model, X[test], y[test])\n",
    "            scores.append(score)\n",
    "\n",
    "        return np.mean(scores)\n",
    "\n",
    "    bo = BayesianOptimization(optimize, search_space_internal, verbose=verbose)\n",
    "    bo.maximize(n_iter=bo_rounds)\n",
    "\n",
    "    best_params = bo.res['max']['max_params']\n",
    "    best_score = bo.res['max']['max_val']\n",
    "\n",
    "    return transform_params(best_params), best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx = df_all.source == TRAIN\n",
    "ho_idx = df_all.source == HOLD_OUT\n",
    "\n",
    "y = df_all[train_idx].Party.astype(int).values\n",
    "y_val = df_all[ho_idx].Party.astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmf_top_15_notsel_nmf 0.638\n",
      "nmf_top_5_notsel_nmf 0.604\n",
      "svd_top_5_notsel_nmf 0.614\n",
      "mtv 0.628\n",
      "svd_top_15_notsel_svd 0.622\n",
      "alternative 0.642\n",
      "oh_top_notsel_svd 0.628\n",
      "oh_top_notsel_nmf 0.626\n",
      "nmf_top_5 0.604\n",
      "svd_top_10_notsel_svd 0.646\n",
      "svd_all_50 0.632\n",
      "svd_all_15 0.592\n",
      "svd_top_10 0.636\n",
      "svd_top_15 0.632\n",
      "svd_top_5_notsel_svd 0.618\n",
      "nmf_top_10_notsel_nmf 0.616\n",
      "svd_top_15_notsel_nmf 0.63\n",
      "svd_top_5 0.6\n",
      "oh_all 0.62\n",
      "nmf_top_15_notsel_svd 0.642\n",
      "nmf_top_5_notsel_svd 0.608\n",
      "svd_top_10_notsel_nmf 0.634\n",
      "nmf_all_50 0.624\n",
      "svd_all_25 0.614\n",
      "nmf_top_15 0.634\n",
      "nmf_top_10_notsel_svd 0.614\n",
      "nmf_all_15 0.554\n",
      "nmf_top_10 0.6\n",
      "nmf_all_25 0.572\n",
      "oh_top 0.63\n"
     ]
    }
   ],
   "source": [
    "def svm_eval(svm, X_val, y_val):\n",
    "    pred = svm.decision_function(X_val)\n",
    "    pred = 1 / (1 + np.exp(-pred))\n",
    "    return auc(y_val, pred)\n",
    "\n",
    "svm_models = []\n",
    "\n",
    "for ds_name, dataset in datasets.items():\n",
    "    X = dataset[train_idx.values]\n",
    "    X_val = dataset[ho_idx.values]\n",
    "    svm = LinearSVC()\n",
    "    svm_search_space = {'C': (0.00005, 1)}\n",
    "\n",
    "    best_params, best_score = find_best_params(X, y, svm, svm_eval, svm_search_space, bo_rounds=10)\n",
    "    svm.set_params(**best_params)\n",
    "    svm.fit(X, y)\n",
    "\n",
    "    y_pred = svm.predict(X_val).astype(int)\n",
    "    acc = (y_val == y_pred).mean()\n",
    "\n",
    "    svm_models.append((ds_name, best_params, svm, acc))\n",
    "    print ds_name, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nmf_top_15_notsel_nmf 0.604\n",
      "nmf_top_5_notsel_nmf 0.58\n",
      "svd_top_5_notsel_nmf 0.614\n",
      "mtv 0.638\n",
      "svd_top_15_notsel_svd 0.642\n",
      "alternative 0.638\n",
      "oh_top_notsel_svd 0.636\n",
      "oh_top_notsel_nmf 0.638\n",
      "nmf_top_5 0.586\n",
      "svd_top_10_notsel_svd 0.62\n",
      "svd_all_50 0.61\n",
      "svd_all_15 0.566\n",
      "svd_top_10 0.608\n",
      "svd_top_15 0.63\n",
      "svd_top_5_notsel_svd 0.598\n",
      "nmf_top_10_notsel_nmf 0.598\n",
      "svd_top_15_notsel_nmf 0.63\n",
      "svd_top_5 0.612\n",
      "oh_all 0.608\n",
      "nmf_top_15_notsel_svd 0.56\n",
      "nmf_top_5_notsel_svd 0.548\n",
      "svd_top_10_notsel_nmf 0.608\n",
      "nmf_all_50 0.53\n",
      "svd_all_25 0.606\n",
      "nmf_top_15 0.614\n",
      "nmf_top_10_notsel_svd 0.56\n",
      "nmf_all_15 0.556\n",
      "nmf_top_10 0.582\n",
      "nmf_all_25 0.598\n",
      "oh_top 0.634\n"
     ]
    }
   ],
   "source": [
    "def sklearn_standard_eval(m, X_val, y_val):\n",
    "    pred = m.predict_proba(X_val)[:, 1]\n",
    "    return auc(y_val, pred)\n",
    "\n",
    "svm_rbf_models = []\n",
    "\n",
    "for ds_name, dataset in datasets.items():\n",
    "    X = dataset[train_idx.values]\n",
    "    X_val = dataset[ho_idx.values]\n",
    "    svm = SVC(kernel='rbf', probability=True)\n",
    "    svm_search_space = {'C': (0.00005, 2)}\n",
    "\n",
    "    best_params, best_score = find_best_params(X, y, svm, sklearn_standard_eval, svm_search_space, bo_rounds=7)\n",
    "    svm.set_params(**best_params)\n",
    "    svm.fit(X, y)\n",
    "\n",
    "    y_pred = svm.predict(X_val).astype(int)\n",
    "    acc = (y_val == y_pred).mean()\n",
    "\n",
    "    svm_rbf_models.append((ds_name, best_params, svm, acc))\n",
    "    print ds_name, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_params = {\n",
      "    'nmf_top_15_notsel_nmf': {'C': 0.69321305571720226}, # 0.638\n",
      "    'nmf_top_5_notsel_nmf': {'C': 0.91349932602059136}, # 0.604\n",
      "    'svd_top_5_notsel_nmf': {'C': 0.15167154118755863}, # 0.614\n",
      "    'mtv': {'C': 0.023722913966058645}, # 0.628\n",
      "    'svd_top_15_notsel_svd': {'C': 0.098033592004883971}, # 0.622\n",
      "    'alternative': {'C': 0.42890651105294347}, # 0.642\n",
      "    'oh_top_notsel_svd': {'C': 0.023837630761856292}, # 0.628\n",
      "    'oh_top_notsel_nmf': {'C': 0.071723987188209382}, # 0.626\n",
      "    'nmf_top_5': {'C': 1.0}, # 0.604\n",
      "    'svd_top_10_notsel_svd': {'C': 0.07645076102888701}, # 0.646\n",
      "    'svd_all_50': {'C': 0.97924085163206098}, # 0.632\n",
      "    'svd_all_15': {'C': 0.19273835898510619}, # 0.592\n",
      "    'svd_top_10': {'C': 0.33907125526716581}, # 0.636\n",
      "    'svd_top_15': {'C': 0.93863689565760577}, # 0.632\n",
      "    'svd_top_5_notsel_svd': {'C': 0.052262222410459122}, # 0.618\n",
      "    'nmf_top_10_notsel_nmf': {'C': 0.60419796734036824}, # 0.616\n",
      "    'svd_top_15_notsel_nmf': {'C': 0.073847522576564878}, # 0.630\n",
      "    'svd_top_5': {'C': 0.02085284132838814}, # 0.600\n",
      "    'oh_all': {'C': 0.0026402810121232624}, # 0.620\n",
      "    'nmf_top_15_notsel_svd': {'C': 0.97759048052356123}, # 0.642\n",
      "    'nmf_top_5_notsel_svd': {'C': 0.95225048665533629}, # 0.608\n",
      "    'svd_top_10_notsel_nmf': {'C': 0.15231137972577216}, # 0.634\n",
      "    'nmf_all_50': {'C': 0.99903529644260691}, # 0.624\n",
      "    'svd_all_25': {'C': 0.45011573705300428}, # 0.614\n",
      "    'nmf_top_15': {'C': 0.40958024992915704}, # 0.634\n",
      "    'nmf_top_10_notsel_svd': {'C': 0.80744274390613024}, # 0.614\n",
      "    'nmf_all_15': {'C': 0.17314403233766912}, # 0.554\n",
      "    'nmf_top_10': {'C': 0.9143573939562053}, # 0.600\n",
      "    'nmf_all_25': {'C': 1.0}, # 0.572\n",
      "    'oh_top': {'C': 0.21049266255578908}, # 0.630\n",
      "}\n",
      "\n",
      "svm_rbf_params = {\n",
      "    'nmf_top_15_notsel_nmf': {'C': 2.0}, # 0.604\n",
      "    'nmf_top_5_notsel_nmf': {'C': 2.0}, # 0.580\n",
      "    'svd_top_5_notsel_nmf': {'C': 2.0}, # 0.614\n",
      "    'mtv': {'C': 2.0}, # 0.638\n",
      "    'svd_top_15_notsel_svd': {'C': 0.99463539553853331}, # 0.642\n",
      "    'alternative': {'C': 0.097029755861334874}, # 0.638\n",
      "    'oh_top_notsel_svd': {'C': 0.99292456077965718}, # 0.636\n",
      "    'oh_top_notsel_nmf': {'C': 2.0}, # 0.638\n",
      "    'nmf_top_5': {'C': 2.0}, # 0.586\n",
      "    'svd_top_10_notsel_svd': {'C': 0.54599603497527593}, # 0.620\n",
      "    'svd_all_50': {'C': 0.75931063513043806}, # 0.610\n",
      "    'svd_all_15': {'C': 0.62908704507633795}, # 0.566\n",
      "    'svd_top_10': {'C': 0.4299317488628388}, # 0.608\n",
      "    'svd_top_15': {'C': 0.84106683216597722}, # 0.630\n",
      "    'svd_top_5_notsel_svd': {'C': 0.64276277266668769}, # 0.598\n",
      "    'nmf_top_10_notsel_nmf': {'C': 2.0}, # 0.598\n",
      "    'svd_top_15_notsel_nmf': {'C': 1.4769677050229639}, # 0.630\n",
      "    'svd_top_5': {'C': 1.7310963933072609}, # 0.612\n",
      "    'oh_all': {'C': 0.94743922501636857}, # 0.608\n",
      "    'nmf_top_15_notsel_svd': {'C': 2.0}, # 0.560\n",
      "    'nmf_top_5_notsel_svd': {'C': 2.0}, # 0.548\n",
      "    'svd_top_10_notsel_nmf': {'C': 1.5588057695061843}, # 0.608\n",
      "    'nmf_all_50': {'C': 1.0983406391792048}, # 0.530\n",
      "    'svd_all_25': {'C': 0.62237267586232325}, # 0.606\n",
      "    'nmf_top_15': {'C': 2.0}, # 0.614\n",
      "    'nmf_top_10_notsel_svd': {'C': 2.0}, # 0.560\n",
      "    'nmf_all_15': {'C': 2.0}, # 0.556\n",
      "    'nmf_top_10': {'C': 2.0}, # 0.582\n",
      "    'nmf_all_25': {'C': 2.0}, # 0.598\n",
      "    'oh_top': {'C': 2.0}, # 0.634\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params_set = {\n",
    "    'svm_params': svm_models,\n",
    "    'svm_rbf_params': svm_rbf_models,\n",
    "}\n",
    "\n",
    "for dict_name, models in params_set.items():\n",
    "    print dict_name, '= {'\n",
    "    for ds_name, best_params, model, acc in models:\n",
    "        print \"    '%s': %s, # %0.3f\" % (ds_name, best_params, acc)\n",
    "    print '}'\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "    'nmf_top_15_notsel_nmf': {'C': 0.69321305571720226}, # 0.638\n",
    "    'nmf_top_5_notsel_nmf': {'C': 0.91349932602059136}, # 0.604\n",
    "    'svd_top_5_notsel_nmf': {'C': 0.15167154118755863}, # 0.614\n",
    "    'svd_top_15_notsel_svd': {'C': 0.098033592004883971}, # 0.622\n",
    "    'oh_top_notsel_svd': {'C': 0.023837630761856292}, # 0.628\n",
    "    'oh_top_notsel_nmf': {'C': 0.071723987188209382}, # 0.626\n",
    "    'nmf_top_5': {'C': 1.0}, # 0.604\n",
    "    'svd_top_10_notsel_svd': {'C': 0.07645076102888701}, # 0.646\n",
    "    'svd_all_50': {'C': 0.97924085163206098}, # 0.632\n",
    "    'svd_all_15': {'C': 0.19273835898510619}, # 0.592\n",
    "    'svd_top_10': {'C': 0.33907125526716581}, # 0.636\n",
    "    'svd_top_15': {'C': 0.93863689565760577}, # 0.632\n",
    "    'svd_top_5_notsel_svd': {'C': 0.052262222410459122}, # 0.618\n",
    "    'nmf_top_10_notsel_nmf': {'C': 0.60419796734036824}, # 0.616\n",
    "    'svd_top_15_notsel_nmf': {'C': 0.073847522576564878}, # 0.630\n",
    "    'svd_top_5': {'C': 0.02085284132838814}, # 0.600\n",
    "    'oh_all': {'C': 0.0026402810121232624}, # 0.620\n",
    "    'nmf_top_15_notsel_svd': {'C': 0.97759048052356123}, # 0.642\n",
    "    'nmf_top_5_notsel_svd': {'C': 0.95225048665533629}, # 0.608\n",
    "    'svd_top_10_notsel_nmf': {'C': 0.15231137972577216}, # 0.634\n",
    "    'nmf_all_50': {'C': 0.99903529644260691}, # 0.624\n",
    "    'svd_all_25': {'C': 0.45011573705300428}, # 0.614\n",
    "    'nmf_top_15': {'C': 0.40958024992915704}, # 0.634\n",
    "    'nmf_top_10_notsel_svd': {'C': 0.80744274390613024}, # 0.614\n",
    "    'nmf_all_15': {'C': 0.17314403233766912}, # 0.554\n",
    "    'nmf_top_10': {'C': 0.9143573939562053}, # 0.600\n",
    "    'nmf_all_25': {'C': 1.0}, # 0.572\n",
    "    'oh_top': {'C': 0.21049266255578908}, # 0.630\n",
    "}\n",
    "\n",
    "svm_rbf_params = {\n",
    "    'nmf_top_15_notsel_nmf': {'C': 2.0}, # 0.604\n",
    "    'nmf_top_5_notsel_nmf': {'C': 2.0}, # 0.580\n",
    "    'svd_top_5_notsel_nmf': {'C': 2.0}, # 0.614\n",
    "    'svd_top_15_notsel_svd': {'C': 0.99463539553853331}, # 0.642\n",
    "    'oh_top_notsel_svd': {'C': 0.99292456077965718}, # 0.636\n",
    "    'oh_top_notsel_nmf': {'C': 2.0}, # 0.638\n",
    "    'nmf_top_5': {'C': 2.0}, # 0.586\n",
    "    'svd_top_10_notsel_svd': {'C': 0.54599603497527593}, # 0.620\n",
    "    'svd_all_50': {'C': 0.75931063513043806}, # 0.610\n",
    "    'svd_all_15': {'C': 0.62908704507633795}, # 0.566\n",
    "    'svd_top_10': {'C': 0.4299317488628388}, # 0.608\n",
    "    'svd_top_15': {'C': 0.84106683216597722}, # 0.630\n",
    "    'svd_top_5_notsel_svd': {'C': 0.64276277266668769}, # 0.598\n",
    "    'nmf_top_10_notsel_nmf': {'C': 2.0}, # 0.598\n",
    "    'svd_top_15_notsel_nmf': {'C': 1.4769677050229639}, # 0.630\n",
    "    'svd_top_5': {'C': 1.7310963933072609}, # 0.612\n",
    "    'oh_all': {'C': 0.94743922501636857}, # 0.608\n",
    "    'nmf_top_15_notsel_svd': {'C': 2.0}, # 0.560\n",
    "    'nmf_top_5_notsel_svd': {'C': 2.0}, # 0.548\n",
    "    'svd_top_10_notsel_nmf': {'C': 1.5588057695061843}, # 0.608\n",
    "    'nmf_all_50': {'C': 1.0983406391792048}, # 0.530\n",
    "    'svd_all_25': {'C': 0.62237267586232325}, # 0.606\n",
    "    'nmf_top_15': {'C': 2.0}, # 0.614\n",
    "    'nmf_top_10_notsel_svd': {'C': 2.0}, # 0.560\n",
    "    'nmf_all_15': {'C': 2.0}, # 0.556\n",
    "    'nmf_top_10': {'C': 2.0}, # 0.582\n",
    "    'nmf_all_25': {'C': 2.0}, # 0.598\n",
    "    'oh_top': {'C': 2.0}, # 0.634\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Classifier\n",
    "from heamy.pipeline import ModelsPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_predict_proba(self, X_test):\n",
    "    pred = self.decision_function(X_test)\n",
    "    return 1 / (1 + np.exp(-pred))\n",
    "\n",
    "LinearSVC.predict_proba = svm_predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heamy_datasets = {}\n",
    "for ds_name, dataset in datasets.items():\n",
    "    X = dataset[train_idx.values]\n",
    "    X_val = dataset[ho_idx.values]\n",
    "    heamy_datasets[ds_name] = Dataset(X, y, X_val)\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for ds_name, params in svm_params.items():\n",
    "    clf = Classifier(dataset=heamy_datasets[ds_name], estimator=LinearSVC, parameters=params,\n",
    "                     name='svm_lin_' + ds_name)\n",
    "    classifiers.append(clf)\n",
    "\n",
    "for ds_name, params in svm_rbf_params.items():\n",
    "    params = params.copy()\n",
    "    params['probability'] = True\n",
    "    clf = Classifier(dataset=heamy_datasets[ds_name], estimator=SVC, parameters=params,\n",
    "                     name='svm_rbf_' + ds_name)\n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = ModelsPipeline(*classifiers)\n",
    "stacked = pipeline.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = stacked.X_train.corr()\n",
    "\n",
    "no, comps = scipy.sparse.csgraph.connected_components(corr.values >= 0.95)\n",
    "uncorrelated = pd.DataFrame({'variable': corr.columns, 'component': comps}).groupby('component').head(1).variable\n",
    "use = natsorted(uncorrelated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: roc_auc_score\n",
      "Folds accuracy: [0.68730924945499838, 0.67881955409587569, 0.70593090988381146, 0.64980679212088832, 0.66124964976183809, 0.69852550685701786, 0.68057592113062748, 0.68678438835678401, 0.71548647633358375, 0.7036030341340076]\n",
      "Mean accuracy: 0.686809148213\n",
      "Standard Deviation: 0.0193202959281\n",
      "Variance: 0.00037327383475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_decorr = Dataset(X_train=stacked.X_train[use], y_train=stacked.y_train, X_test=stacked.X_test[use])\n",
    "stacker = Classifier(dataset=stacked_decorr, estimator=LogisticRegression)\n",
    "\n",
    "_ = stacker.validate(k=10, scorer=roc_auc_score)\n",
    "stacked_result = stacker.predict()\n",
    "stacked_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44999999999999996"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEPCAYAAABP1MOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe8491f2f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = []\n",
    "for i in np.linspace(0.30, 0.60, 31):\n",
    "    stacked_pred = (stacked_result >= i).astype(int)\n",
    "    acc = (y_val == stacked_pred).mean()\n",
    "    thresholds.append((i, acc))\n",
    "\n",
    "thresholds = pd.DataFrame(thresholds, columns=['threshold', 'accuracy'])\n",
    "thresholds['mean_accuracy'] = thresholds.accuracy.rolling(5, center=True).mean()\n",
    "ax = thresholds.plot(kind='line', x='threshold', y='accuracy')\n",
    "thresholds.plot(kind='line', x='threshold', y='mean_accuracy', ax=ax)\n",
    "\n",
    "thresholds.threshold[thresholds.mean_accuracy.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_train_idx = df_all.source != TEST\n",
    "full_test_idx = df_all.source == TEST\n",
    "y_full = df_all[full_train_idx].Party.astype(int).values\n",
    "\n",
    "heamy_datasets_full = {}\n",
    "for ds_name, dataset in datasets.items():\n",
    "    X_full = dataset[full_train_idx.values]\n",
    "    X_test = dataset[full_test_idx.values]\n",
    "    heamy_datasets_full[ds_name] = Dataset(X_full, y_full, X_test)\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for ds_name, params in svm_params.items():\n",
    "    clf = Classifier(dataset=heamy_datasets_full[ds_name], estimator=LinearSVC, parameters=params,\n",
    "                     name='svm_lin_' + ds_name)\n",
    "    classifiers.append(clf)\n",
    "\n",
    "for ds_name, params in svm_rbf_params.items():\n",
    "    params = params.copy()\n",
    "    params['probability'] = True\n",
    "    clf = Classifier(dataset=heamy_datasets_full[ds_name], estimator=SVC, parameters=params,\n",
    "                     name='svm_rbf_' + ds_name)\n",
    "    classifiers.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = ModelsPipeline(*classifiers)\n",
    "stacked = pipeline.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stacked_decorr = Dataset(X_train=stacked.X_train[use], y_train=stacked.y_train, X_test=stacked.X_test[use])\n",
    "stacker = Classifier(dataset=stacked_decorr, estimator=LogisticRegression)\n",
    "stacked_result = stacker.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = (stacked_result >= 0.45).astype(int)\n",
    "y_pred = party_encoder.inverse_transform(y_pred)\n",
    "\n",
    "user_ids = df_all.USER_ID[df_all.source == TEST].values\n",
    "\n",
    "result = pd.DataFrame({'USER_ID': user_ids, 'Predictions': y_pred})\n",
    "result.to_csv('heamy3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
